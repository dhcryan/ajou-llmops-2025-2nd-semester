{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee5c5ac",
   "metadata": {},
   "source": [
    "# Assignment 01 â€” Email & Document Writer with Langfuse\n",
    "\n",
    "## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”\n",
    "**ì£¼ì œ**: ì´ë©”ì¼Â·ë¬¸ì„œ ìë™ ì‘ì„±  \n",
    "**ëª©ì **: Prompt ë²„ì „ ê´€ë¦¬ â†’ ë°°í¬ â†’ Tracing â†’ Evaluation ì „ì²´ ì‚¬ì´í´ êµ¬í˜„\n",
    "\n",
    "### í‰ê°€ ì§€í‘œ\n",
    "1. **í˜•ì‹ ì¤€ìˆ˜ìœ¨** (Schema Compliance): í•„ìˆ˜ êµ¬ì¡° ìš”ì†Œ í¬í•¨ ì—¬ë¶€\n",
    "2. **í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ ** (Mandatory Items): must_include ë¦¬ìŠ¤íŠ¸ ì™„ì„±ë„\n",
    "3. **í†¤ ì¼ì¹˜ë„** (Tone Consistency): LLM-as-Judgeë¡œ 0-5ì  í‰ê°€\n",
    "4. **ê¸¸ì´ ì œí•œ ì¤€ìˆ˜** (Length Control): max_length ì´ë‚´ ì‘ì„± ì—¬ë¶€\n",
    "5. **í¸ì§‘ í•„ìš”ë„** (Edit Need): LLM-as-Judgeë¡œ 0-5ì  í‰ê°€ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "\n",
    "### ë²„ì „ ë¹„êµ\n",
    "- **V1.0.0 (dev)**: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ - ê°„ë‹¨í•œ ì…ë ¥ë§Œ ë°›ìŒ\n",
    "- **V2.0.0 (production)**: ê°œì„  í”„ë¡¬í”„íŠ¸ - ìƒì„¸ ì œì•½ì¡°ê±´, í•„ìˆ˜ ìš”ì†Œ ê²€ì¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683a223",
   "metadata": {},
   "source": [
    "## ğŸ“¦ í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78979a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse[all] in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (3.6.1)\n",
      "\u001b[33mWARNING: langfuse 3.6.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: backoff>=1.10.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (2.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.17.2)\n",
      "Requirement already satisfied: anyio in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse[all]) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse[all]) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse[all]) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse[all]) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse[all]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse[all]) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2->langfuse[all]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2->langfuse[all]) (2.2.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse[all]) (3.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from anyio->httpx<1.0,>=0.15.4->langfuse[all]) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langfuse openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1ef04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment Check:\n",
      "  Langfuse Host: https://cloud.langfuse.com\n",
      "  Langfuse Public Key: âœ“\n",
      "  Langfuse Secret Key: âœ“\n",
      "  OpenAI API Key: âœ“\n",
      "\n",
      "âœ… Langfuse ì—°ê²° ì„±ê³µ!\n",
      "\n",
      "âœ… Langfuse ì—°ê²° ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "from openai import OpenAI\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ ì„¤ì •\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"âœ… Environment Check:\")\n",
    "print(f\"  Langfuse Host: {LANGFUSE_HOST}\")\n",
    "print(f\"  Langfuse Public Key: {'âœ“' if LANGFUSE_PUBLIC_KEY else 'âœ—'}\")\n",
    "print(f\"  Langfuse Secret Key: {'âœ“' if LANGFUSE_SECRET_KEY else 'âœ—'}\")\n",
    "print(f\"  OpenAI API Key: {'âœ“' if OPENAI_API_KEY else 'âœ—'}\")\n",
    "\n",
    "# Langfuse ì´ˆê¸°í™”\n",
    "langfuse = Langfuse(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Langfuse wrapper ì‚¬ìš©)\n",
    "from langfuse.openai import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "print(\"\\nâœ… Langfuse ì—°ê²° ì„±ê³µ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086be95",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset ë¡œë“œ ë° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5d3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: 15ê°œ ìƒ˜í”Œ\n",
      "\n",
      "ìƒ˜í”Œ #1:\n",
      "{\n",
      "  \"id\": \"e001\",\n",
      "  \"input\": {\n",
      "    \"purpose\": \"ì¶œì¥ ë³´ê³ ì„œ\",\n",
      "    \"audience\": \"ì„ì›ì§„\",\n",
      "    \"key_points\": [\n",
      "      \"ì˜ˆì‚° ì§‘í–‰ í˜„í™©\",\n",
      "      \"ì£¼ìš” ë¯¸íŒ… ê²°ê³¼\",\n",
      "      \"ë¦¬ìŠ¤í¬ ìš”ì¸\"\n",
      "    ]\n",
      "  },\n",
      "  \"reference\": {\n",
      "    \"style\": \"formal\",\n",
      "    \"must_include\": [\n",
      "      \"ì˜ˆì‚° ìˆ˜ì¹˜\",\n",
      "      \"ë¦¬ìŠ¤í¬ 2ê°œ ì´ìƒ\",\n",
      "      \"í–¥í›„ ì¡°ì¹˜ì‚¬í•­\"\n",
      "    ],\n",
      "    \"tone\": \"professional\",\n",
      "    \"max_length\": 500\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# JSONL ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "dataset_path = Path(\"datasets/email_writer_eval.jsonl\")\n",
    "\n",
    "def load_dataset(path: Path) -> List[Dict]:\n",
    "    \"\"\"JSONL íŒŒì¼ ë¡œë“œ\"\"\"\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "dataset = load_dataset(dataset_path)\n",
    "print(f\"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset)}ê°œ ìƒ˜í”Œ\")\n",
    "print(f\"\\nìƒ˜í”Œ #1:\")\n",
    "print(json.dumps(dataset[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0adb46",
   "metadata": {},
   "source": [
    "## ğŸ”§ Prompt ë²„ì „ ë¡œë“œ (V1 & V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995cbc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… V1 Prompt ë¡œë“œ ì™„ë£Œ\n",
      "  System: 132 chars\n",
      "  User Template: 204 chars\n",
      "\n",
      "âœ… V2 Prompt ë¡œë“œ ì™„ë£Œ\n",
      "  System: 873 chars\n",
      "  User Template: 647 chars\n"
     ]
    }
   ],
   "source": [
    "# .prompty íŒŒì¼ íŒŒì‹± í•¨ìˆ˜\n",
    "def parse_prompty_file(path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"Parse .prompty file and extract metadata + prompt\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split frontmatter and prompt content\n",
    "    parts = content.split('---')\n",
    "    if len(parts) >= 3:\n",
    "        # frontmatter = parts[1]  # YAML metadata (not parsing for now)\n",
    "        prompt_content = parts[2].strip()\n",
    "    else:\n",
    "        prompt_content = content\n",
    "    \n",
    "    # Extract system and user sections\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    \n",
    "    if \"system:\" in prompt_content:\n",
    "        parts = prompt_content.split(\"user:\", 1)\n",
    "        system_prompt = parts[0].replace(\"system:\", \"\").strip()\n",
    "        if len(parts) > 1:\n",
    "            user_prompt = parts[1].strip()\n",
    "    else:\n",
    "        user_prompt = prompt_content.strip()\n",
    "    \n",
    "    return {\n",
    "        \"system\": system_prompt,\n",
    "        \"user_template\": user_prompt\n",
    "    }\n",
    "\n",
    "# V1, V2 í”„ë¡¬í”„íŠ¸ ë¡œë“œ\n",
    "prompt_v1 = parse_prompty_file(Path(\"prompts/email_writer_v1.0.prompty\"))\n",
    "prompt_v2 = parse_prompty_file(Path(\"prompts/email_writer_v2.0.prompty\"))\n",
    "\n",
    "print(\"âœ… V1 Prompt ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  System: {len(prompt_v1['system'])} chars\")\n",
    "print(f\"  User Template: {len(prompt_v1['user_template'])} chars\")\n",
    "print(\"\\nâœ… V2 Prompt ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  System: {len(prompt_v2['system'])} chars\")\n",
    "print(f\"  User Template: {len(prompt_v2['user_template'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad9c7f",
   "metadata": {},
   "source": [
    "## ğŸš€ Langfuseì— Prompt ë°°í¬ (Versioning)\n",
    "\n",
    "**ì¤‘ìš”**: Langfuse UIì—ì„œ ìˆ˜ë™ìœ¼ë¡œ Promptë¥¼ ìƒì„±í•œ í›„, ì—¬ê¸°ì„œ fetchí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "ë˜ëŠ” APIë¡œ ì§ì ‘ ìƒì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724304fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… V1 Prompt ë°°í¬ ì™„ë£Œ (dev label)\n",
      "âœ… V2 Prompt ë°°í¬ ì™„ë£Œ (production label)\n",
      "âœ… V2 Prompt ë°°í¬ ì™„ë£Œ (production label)\n",
      "\n",
      "ğŸ”„ Langfuseì— Prompt ë™ê¸°í™” ì™„ë£Œ\n",
      "\n",
      "ğŸ”„ Langfuseì— Prompt ë™ê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Langfuseì— Prompt ìƒì„±/ì—…ë°ì´íŠ¸\n",
    "# ì°¸ê³ : Langfuse Python SDKì—ì„œëŠ” create_prompt() ë©”ì„œë“œ ì‚¬ìš©\n",
    "\n",
    "PROMPT_NAME = \"email-writer\"\n",
    "\n",
    "# V1 ë°°í¬ (dev ë¼ë²¨)\n",
    "try:\n",
    "    langfuse.create_prompt(\n",
    "        name=PROMPT_NAME,\n",
    "        prompt=prompt_v1['user_template'],\n",
    "        config={\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 800,\n",
    "            \"system_message\": prompt_v1['system']\n",
    "        },\n",
    "        labels=[\"dev\"],\n",
    "        tags=[\"v1.0.0\", \"basic\", \"email-writing\"]\n",
    "    )\n",
    "    print(\"âœ… V1 Prompt ë°°í¬ ì™„ë£Œ (dev label)\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  V1 Prompt ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# V2 ë°°í¬ (production ë¼ë²¨)\n",
    "try:\n",
    "    langfuse.create_prompt(\n",
    "        name=PROMPT_NAME,\n",
    "        prompt=prompt_v2['user_template'],\n",
    "        config={\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"system_message\": prompt_v2['system']\n",
    "        },\n",
    "        labels=[\"production\"],\n",
    "        tags=[\"v2.0.0\", \"professional\", \"email-writing\", \"structured\"]\n",
    "    )\n",
    "    print(\"âœ… V2 Prompt ë°°í¬ ì™„ë£Œ (production label)\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  V2 Prompt ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# Flush to ensure prompts are created\n",
    "langfuse.flush()\n",
    "time.sleep(2)\n",
    "print(\"\\nğŸ”„ Langfuseì— Prompt ë™ê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83bcf4",
   "metadata": {},
   "source": [
    "## ğŸ“ Email ìƒì„± í•¨ìˆ˜ (with Tracing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca305a9",
   "metadata": {},
   "source": [
    "Summarized conversation historyì„ íƒí•˜ì‹  ì½”ë“œëŠ” **Langfuseì— Promptë¥¼ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ë°°í¬(ìƒì„±)í•˜ëŠ” ì½”ë“œ**ì…ë‹ˆë‹¤. ê° ë¶€ë¶„ì„ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "## ğŸ¯ ì½”ë“œì˜ ëª©ì \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langfuse.create_prompt(\n",
    "#     name=\"email-writer\",\n",
    "#     prompt=prompt_v1['user_template'],\n",
    "#     config={...},\n",
    "#     labels=[\"dev\"],\n",
    "#     tags=[\"v1.0.0\", \"basic\", \"email-writing\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558c2e7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ì´ ì½”ë“œëŠ” **Langfuse í”Œë«í¼ì— í”„ë¡¬í”„íŠ¸ë¥¼ ë“±ë¡**í•˜ì—¬:\n",
    "1. **ë²„ì „ ê´€ë¦¬**: í”„ë¡¬í”„íŠ¸ë¥¼ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ê³  ë²„ì „ì„ ì¶”ì \n",
    "2. **ì¬ì‚¬ìš©ì„±**: ì—¬ëŸ¬ ê³³ì—ì„œ ê°™ì€ í”„ë¡¬í”„íŠ¸ë¥¼ fetchí•˜ì—¬ ì‚¬ìš©\n",
    "3. **ë¼ë²¨ë§**: `dev`ì™€ `production` í™˜ê²½ êµ¬ë¶„\n",
    "4. **ì¶”ì **: ì–´ë–¤ í”„ë¡¬í”„íŠ¸ ë²„ì „ì´ ì–´ë–¤ ê²°ê³¼ë¥¼ ëƒˆëŠ”ì§€ ì¶”ì  ê°€ëŠ¥\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ íŒŒë¼ë¯¸í„° ì„¤ëª…\n",
    "\n",
    "### 1. `name=\"email-writer\"`\n",
    "- **í”„ë¡¬í”„íŠ¸ ì‹ë³„ì**: Langfuseì—ì„œ ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì´ë¦„\n",
    "- ë‚˜ì¤‘ì— `langfuse.get_prompt(\"email-writer\", label=\"dev\")`ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŒ\n",
    "\n",
    "### 2. `prompt=prompt_v1['user_template']`\n",
    "- **ì‹¤ì œ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸**: `.prompty` íŒŒì¼ì—ì„œ íŒŒì‹±í•œ ì‚¬ìš©ì ë©”ì‹œì§€ í…œí”Œë¦¿\n",
    "- Jinja2 í˜•ì‹ì˜ í…œí”Œë¦¿ ë¬¸ìì—´ (ì˜ˆ: `{{purpose}}`, `{{key_points}}`)\n",
    "\n",
    "### 3. `config={...}`\n",
    "- **ëª¨ë¸ ì„¤ì •**: OpenAI í˜¸ì¶œ ì‹œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„°ë“¤\n",
    "  ```python\n",
    "  {\n",
    "      \"model\": \"gpt-4o-mini\",        # ì‚¬ìš©í•  ëª¨ë¸\n",
    "      \"temperature\": 0.7,             # ì°½ì˜ì„± ì •ë„ (0-1)\n",
    "      \"max_tokens\": 800,              # ìµœëŒ€ ì¶œë ¥ ê¸¸ì´\n",
    "      \"system_message\": prompt_v1['system']  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "  }\n",
    "  ```\n",
    "\n",
    "### 4. `labels=[\"dev\"]` (V1) / `[\"production\"]` (V2)\n",
    "- **í™˜ê²½ ë¼ë²¨**: ê°œë°œ/ìš´ì˜ í™˜ê²½ êµ¬ë¶„\n",
    "  - `dev`: í…ŒìŠ¤íŠ¸ ì¤‘ì¸ ë²„ì „ (V1)\n",
    "  - `production`: ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ë²„ì „ (V2)\n",
    "- ê°™ì€ ì´ë¦„ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ëŸ¬ ë²„ì „ìœ¼ë¡œ ê´€ë¦¬ ê°€ëŠ¥\n",
    "\n",
    "### 5. `tags=[\"v1.0.0\", \"basic\", \"email-writing\"]`\n",
    "- **ë©”íƒ€ë°ì´í„° íƒœê·¸**: ê²€ìƒ‰, ë¶„ë¥˜, í•„í„°ë§ ìš©ë„\n",
    "  - ë²„ì „ ë²ˆí˜¸: `v1.0.0`, `v2.0.0`\n",
    "  - íŠ¹ì§•: `basic`, `professional`, `structured`\n",
    "  - ì¹´í…Œê³ ë¦¬: `email-writing`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ V1 vs V2 ë¹„êµ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # V1 (ê°œë°œ ë²„ì „)\n",
    "# langfuse.create_prompt(\n",
    "#     name=\"email-writer\",\n",
    "#     labels=[\"dev\"],           # ê°œë°œ í™˜ê²½\n",
    "#     tags=[\"v1.0.0\", \"basic\"], # ê¸°ë³¸ ë²„ì „\n",
    "#     config={\"max_tokens\": 800}\n",
    "# )\n",
    "\n",
    "# # V2 (í”„ë¡œë•ì…˜ ë²„ì „)\n",
    "# langfuse.create_prompt(\n",
    "#     name=\"email-writer\",\n",
    "#     labels=[\"production\"],          # ìš´ì˜ í™˜ê²½\n",
    "#     tags=[\"v2.0.0\", \"professional\"], # ê°œì„  ë²„ì „\n",
    "#     config={\"max_tokens\": 1000}     # ë” ê¸´ ì¶œë ¥ í—ˆìš©\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11985c81",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ë‘ ë²„ì „ ëª¨ë‘ **ê°™ì€ ì´ë¦„** (`email-writer`)ì´ì§€ë§Œ, **ë‹¤ë¥¸ ë¼ë²¨**ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ\n",
    "\n",
    "1. **í”„ë¡¬í”„íŠ¸ ë“±ë¡** (ì§€ê¸ˆ ì‹¤í–‰í•˜ëŠ” ì…€)\n",
    "   ```python\n",
    "   langfuse.create_prompt(name=\"email-writer\", labels=[\"dev\"], ...)\n",
    "   ```\n",
    "\n",
    "2. **ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì˜¤ê¸°**\n",
    "   ```python\n",
    "   # ê°œë°œ ë²„ì „ ì‚¬ìš©\n",
    "   prompt = langfuse.get_prompt(\"email-writer\", label=\"dev\")\n",
    "   \n",
    "   # ìš´ì˜ ë²„ì „ ì‚¬ìš©\n",
    "   prompt = langfuse.get_prompt(\"email-writer\", label=\"production\")\n",
    "   ```\n",
    "\n",
    "3. **Langfuse UIì—ì„œ í™•ì¸**\n",
    "   - ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ í”„ë¡¬í”„íŠ¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ\n",
    "   - ì–´ë–¤ ë²„ì „ì´ ì–¸ì œ ë°°í¬ë˜ì—ˆëŠ”ì§€ ì¶”ì \n",
    "   - A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# except Exception as e:\n",
    "#     print(f\"âš ï¸  V1 Prompt ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac112a19",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **ì¤‘ë³µ ë°©ì§€**: ê°™ì€ ì´ë¦„+ë¼ë²¨ë¡œ ì´ë¯¸ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ\n",
    "- ì¬ì‹¤í–‰ ì‹œ ì˜¤ë¥˜ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰\n",
    "\n",
    "---\n",
    "\n",
    "**ìš”ì•½**: ì´ ì½”ë“œëŠ” `.prompty` íŒŒì¼ì˜ ë‚´ìš©ì„ Langfuse í´ë¼ìš°ë“œì— ì—…ë¡œë“œí•˜ì—¬ **ì¤‘ì•™ ì§‘ì¤‘ì‹ í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬**ë¥¼ ì‹œì‘í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. ë§ˆì¹˜ Gitì— ì½”ë“œë¥¼ pushí•˜ëŠ” ê²ƒì²˜ëŸ¼, í”„ë¡¬í”„íŠ¸ë¥¼ Langfuseì— \"ë°°í¬\"í•˜ëŠ” ê²ƒì´ì£ ! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a415b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Email ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (Tracing í™œì„±í™”)\n"
     ]
    }
   ],
   "source": [
    "def generate_email_v1(\n",
    "    purpose: str,\n",
    "    audience: str,\n",
    "    key_points: List[str],\n",
    "    trace_name: str = \"email-generation-v1\"\n",
    ") -> str:\n",
    "    \"\"\"V1 í”„ë¡¬í”„íŠ¸ë¡œ ì´ë©”ì¼ ìƒì„± (Langfuse Tracing)\"\"\"\n",
    "    \n",
    "    # User prompt êµ¬ì„±\n",
    "    key_points_text = \"\\n\".join([f\"- {point}\" for point in key_points])\n",
    "    user_message = f\"\"\"Write a {purpose} for {audience}.\n",
    "\n",
    "Key points to include:\n",
    "{key_points_text}\n",
    "\n",
    "Please write a professional document that covers all key points clearly and concisely.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_v1['system']},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # OpenAI API í˜¸ì¶œ with Langfuse tracing (ìë™)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages,\n",
    "        # Langfuse metadata\n",
    "        name=trace_name,\n",
    "        metadata={\n",
    "            \"purpose\": purpose,\n",
    "            \"audience\": audience,\n",
    "            \"key_points_count\": len(key_points),\n",
    "            \"version\": \"v1.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def generate_email_v2(\n",
    "    purpose: str,\n",
    "    audience: str,\n",
    "    key_points: List[str],\n",
    "    style: str = \"professional\",\n",
    "    tone: str = \"neutral\",\n",
    "    must_include: List[str] = None,\n",
    "    max_length: int = 500,\n",
    "    trace_name: str = \"email-generation-v2\"\n",
    ") -> str:\n",
    "    \"\"\"V2 í”„ë¡¬í”„íŠ¸ë¡œ ì´ë©”ì¼ ìƒì„± (Langfuse Tracing)\"\"\"\n",
    "    \n",
    "    if must_include is None:\n",
    "        must_include = []\n",
    "    \n",
    "    # User prompt êµ¬ì„± (V2 í…œí”Œë¦¿)\n",
    "    key_points_text = \"\\n\".join([f\"- {point}\" for point in key_points])\n",
    "    must_include_text = \"\\n\".join([f\"âœ“ {item}\" for item in must_include])\n",
    "    \n",
    "    user_message = f\"\"\"**Document Type:** {purpose}\n",
    "**Target Audience:** {audience}\n",
    "\n",
    "**Key Points to Address:**\n",
    "{key_points_text}\n",
    "\n",
    "**Writing Requirements:**\n",
    "- Style: {style}\n",
    "- Tone: {tone}\n",
    "- Maximum Length: {max_length} words\n",
    "\n",
    "**Mandatory Elements (MUST INCLUDE ALL):**\n",
    "{must_include_text}\n",
    "\n",
    "Please generate a professional document that:\n",
    "1. Addresses all key points comprehensively\n",
    "2. Includes ALL mandatory elements listed above\n",
    "3. Maintains the specified style and tone consistently\n",
    "4. Stays within the word limit\n",
    "5. Follows proper business document structure\n",
    "\n",
    "Generate the document now:\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_v2['system']},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # OpenAI API í˜¸ì¶œ with Langfuse tracing (ìë™)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        messages=messages,\n",
    "        # Langfuse metadata\n",
    "        name=trace_name,\n",
    "        metadata={\n",
    "            \"purpose\": purpose,\n",
    "            \"audience\": audience,\n",
    "            \"key_points_count\": len(key_points),\n",
    "            \"style\": style,\n",
    "            \"tone\": tone,\n",
    "            \"must_include_count\": len(must_include),\n",
    "            \"max_length\": max_length,\n",
    "            \"version\": \"v2.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"âœ… Email ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (Tracing í™œì„±í™”)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c24958",
   "metadata": {},
   "source": [
    "## ğŸ§ª V1 & V2 í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìµœì†Œ 5ê±´ì”© Trace ë‚¨ê¸°ê¸°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d3b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” V1 Prompt í…ŒìŠ¤íŠ¸ (5ê±´)\n",
      "============================================================\n",
      "\n",
      "[1/5] ì¶œì¥ ë³´ê³ ì„œ...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1170 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1170 chars)\n",
      "\n",
      "[2/5] í”„ë¡œì íŠ¸ ì œì•ˆì„œ...\n",
      "\n",
      "[2/5] í”„ë¡œì íŠ¸ ì œì•ˆì„œ...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1196 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1196 chars)\n",
      "\n",
      "[3/5] ê³ ê° ë¶ˆë§Œ ì‘ëŒ€ ì´ë©”ì¼...\n",
      "\n",
      "[3/5] ê³ ê° ë¶ˆë§Œ ì‘ëŒ€ ì´ë©”ì¼...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (650 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (650 chars)\n",
      "\n",
      "[4/5] íŒ€ì› ì—…ë¬´ ì§€ì‹œ...\n",
      "\n",
      "[4/5] íŒ€ì› ì—…ë¬´ ì§€ì‹œ...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (427 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (427 chars)\n",
      "\n",
      "[5/5] í˜‘ì—… ì œì•ˆ ì´ë©”ì¼...\n",
      "\n",
      "[5/5] í˜‘ì—… ì œì•ˆ ì´ë©”ì¼...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (440 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (440 chars)\n",
      "\n",
      "============================================================\n",
      "âœ… V1 í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Langfuseì—ì„œ Trace í™•ì¸ ê°€ëŠ¥\n",
      "\n",
      "============================================================\n",
      "âœ… V1 í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Langfuseì—ì„œ Trace í™•ì¸ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# V1 í…ŒìŠ¤íŠ¸: ì²˜ìŒ 5ê°œ ìƒ˜í”Œë¡œ ì‹¤í–‰\n",
    "print(\"ğŸ” V1 Prompt í…ŒìŠ¤íŠ¸ (5ê±´)\\n\" + \"=\"*60)\n",
    "\n",
    "v1_results = []\n",
    "for i, sample in enumerate(dataset[:5], 1):\n",
    "    print(f\"\\n[{i}/5] {sample['input']['purpose']}...\")\n",
    "    \n",
    "    output = generate_email_v1(\n",
    "        purpose=sample['input']['purpose'],\n",
    "        audience=sample['input']['audience'],\n",
    "        key_points=sample['input']['key_points'],\n",
    "        trace_name=f\"v1-test-{sample['id']}\"\n",
    "    )\n",
    "    \n",
    "    v1_results.append({\n",
    "        \"id\": sample['id'],\n",
    "        \"output\": output,\n",
    "        \"reference\": sample['reference']\n",
    "    })\n",
    "    \n",
    "    print(f\"  âœ… ìƒì„± ì™„ë£Œ ({len(output)} chars)\")\n",
    "    time.sleep(0.5)  # Rate limit ë°©ì§€\n",
    "\n",
    "langfuse.flush()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… V1 í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Langfuseì—ì„œ Trace í™•ì¸ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978ea5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” V2 Prompt í…ŒìŠ¤íŠ¸ (5ê±´)\n",
      "============================================================\n",
      "\n",
      "[1/5] ì¶œì¥ ë³´ê³ ì„œ...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1221 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1221 chars)\n",
      "\n",
      "[2/5] í”„ë¡œì íŠ¸ ì œì•ˆì„œ...\n",
      "\n",
      "[2/5] í”„ë¡œì íŠ¸ ì œì•ˆì„œ...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1478 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (1478 chars)\n",
      "\n",
      "[3/5] ê³ ê° ë¶ˆë§Œ ì‘ëŒ€ ì´ë©”ì¼...\n",
      "\n",
      "[3/5] ê³ ê° ë¶ˆë§Œ ì‘ëŒ€ ì´ë©”ì¼...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (771 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (771 chars)\n",
      "\n",
      "[4/5] íŒ€ì› ì—…ë¬´ ì§€ì‹œ...\n",
      "\n",
      "[4/5] íŒ€ì› ì—…ë¬´ ì§€ì‹œ...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (609 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (609 chars)\n",
      "\n",
      "[5/5] í˜‘ì—… ì œì•ˆ ì´ë©”ì¼...\n",
      "\n",
      "[5/5] í˜‘ì—… ì œì•ˆ ì´ë©”ì¼...\n",
      "  âœ… ìƒì„± ì™„ë£Œ (841 chars)\n",
      "  âœ… ìƒì„± ì™„ë£Œ (841 chars)\n",
      "\n",
      "============================================================\n",
      "âœ… V2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Langfuseì—ì„œ Trace í™•ì¸ ê°€ëŠ¥\n",
      "\n",
      "============================================================\n",
      "âœ… V2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Langfuseì—ì„œ Trace í™•ì¸ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# V2 í…ŒìŠ¤íŠ¸: ë™ì¼í•œ 5ê°œ ìƒ˜í”Œë¡œ ì‹¤í–‰ (ë¹„êµë¥¼ ìœ„í•´)\n",
    "print(\"ğŸ” V2 Prompt í…ŒìŠ¤íŠ¸ (5ê±´)\\n\" + \"=\"*60)\n",
    "\n",
    "v2_results = []\n",
    "for i, sample in enumerate(dataset[:5], 1):\n",
    "    print(f\"\\n[{i}/5] {sample['input']['purpose']}...\")\n",
    "    \n",
    "    output = generate_email_v2(\n",
    "        purpose=sample['input']['purpose'],\n",
    "        audience=sample['input']['audience'],\n",
    "        key_points=sample['input']['key_points'],\n",
    "        style=sample['reference'].get('style', 'professional'),\n",
    "        tone=sample['reference'].get('tone', 'neutral'),\n",
    "        must_include=sample['reference'].get('must_include', []),\n",
    "        max_length=sample['reference'].get('max_length', 500),\n",
    "        trace_name=f\"v2-test-{sample['id']}\"\n",
    "    )\n",
    "    \n",
    "    v2_results.append({\n",
    "        \"id\": sample['id'],\n",
    "        \"output\": output,\n",
    "        \"reference\": sample['reference']\n",
    "    })\n",
    "    \n",
    "    print(f\"  âœ… ìƒì„± ì™„ë£Œ ({len(output)} chars)\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "langfuse.flush()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… V2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Langfuseì—ì„œ Trace í™•ì¸ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385cec3f",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Langfuse Datasetì— ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871a7f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Langfuse Dataset 'email-writer-eval' ìƒì„± ë° ì—…ë¡œë“œ ì¤‘...\n",
      "\n",
      "âœ… Dataset 'email-writer-eval' ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ“ Dataset ì•„ì´í…œ ì¶”ê°€ ì¤‘...\n",
      "âœ… Dataset 'email-writer-eval' ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ“ Dataset ì•„ì´í…œ ì¶”ê°€ ì¤‘...\n",
      "  ì§„í–‰ë¥ : 5/15\n",
      "  ì§„í–‰ë¥ : 5/15\n",
      "  ì§„í–‰ë¥ : 10/15\n",
      "  ì§„í–‰ë¥ : 10/15\n",
      "  ì§„í–‰ë¥ : 15/15\n",
      "\n",
      "âœ… Dataset ì—…ë¡œë“œ ì™„ë£Œ: 15ê°œ ì•„ì´í…œ\n",
      "   Langfuse UIì—ì„œ 'email-writer-eval' í™•ì¸ ê°€ëŠ¥\n",
      "  ì§„í–‰ë¥ : 15/15\n",
      "\n",
      "âœ… Dataset ì—…ë¡œë“œ ì™„ë£Œ: 15ê°œ ì•„ì´í…œ\n",
      "   Langfuse UIì—ì„œ 'email-writer-eval' í™•ì¸ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# Langfuse Dataset ìƒì„±/ì—…ë°ì´íŠ¸\n",
    "DATASET_NAME = \"email-writer-eval\"\n",
    "\n",
    "print(f\"ğŸ“¤ Langfuse Dataset '{DATASET_NAME}' ìƒì„± ë° ì—…ë¡œë“œ ì¤‘...\\n\")\n",
    "\n",
    "# Step 1: Dataset ë¨¼ì € ìƒì„±\n",
    "try:\n",
    "    langfuse.create_dataset(\n",
    "        name=DATASET_NAME,\n",
    "        description=\"Email & Document Writer í‰ê°€ìš© ë°ì´í„°ì…‹ - 15ê°œ ìƒ˜í”Œ\",\n",
    "        metadata={\n",
    "            \"version\": \"1.0\",\n",
    "            \"created_date\": datetime.now().isoformat(),\n",
    "            \"total_samples\": len(dataset)\n",
    "        }\n",
    "    )\n",
    "    print(f\"âœ… Dataset '{DATASET_NAME}' ìƒì„± ì™„ë£Œ\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Dataset ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì˜¤ë¥˜: {e}\\n\")\n",
    "\n",
    "# Step 2: Datasetì— ì•„ì´í…œ ì¶”ê°€\n",
    "print(\"ğŸ“ Dataset ì•„ì´í…œ ì¶”ê°€ ì¤‘...\")\n",
    "for i, sample in enumerate(dataset, 1):\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=DATASET_NAME,\n",
    "        input=sample['input'],\n",
    "        expected_output=sample['reference'],\n",
    "        metadata={\n",
    "            \"id\": sample['id'],\n",
    "            \"purpose\": sample['input']['purpose']\n",
    "        }\n",
    "    )\n",
    "    if i % 5 == 0:\n",
    "        print(f\"  ì§„í–‰ë¥ : {i}/{len(dataset)}\")\n",
    "\n",
    "langfuse.flush()\n",
    "print(f\"\\nâœ… Dataset ì—…ë¡œë“œ ì™„ë£Œ: {len(dataset)}ê°œ ì•„ì´í…œ\")\n",
    "print(f\"   Langfuse UIì—ì„œ '{DATASET_NAME}' í™•ì¸ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6065653",
   "metadata": {},
   "source": [
    "## ğŸ“Š Evaluation í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb29b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mandatory_items(output: str, must_include: List[str]) -> Dict:\n",
    "    \"\"\"í•„ìˆ˜ í•­ëª© í¬í•¨ ì—¬ë¶€ ì²´í¬ (ì •ëŸ‰)\"\"\"\n",
    "    found_count = sum(1 for item in must_include if item.lower() in output.lower())\n",
    "    total = len(must_include)\n",
    "    \n",
    "    return {\n",
    "        \"mandatory_items_found\": found_count,\n",
    "        \"mandatory_items_total\": total,\n",
    "        \"mandatory_items_rate\": found_count / total if total > 0 else 1.0\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_length(output: str, max_length: int) -> Dict:\n",
    "    \"\"\"ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ ì²´í¬ (ì •ëŸ‰)\"\"\"\n",
    "    word_count = len(output.split())\n",
    "    compliant = word_count <= max_length\n",
    "    \n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"max_length\": max_length,\n",
    "        \"length_compliant\": compliant,\n",
    "        \"length_ratio\": word_count / max_length if max_length > 0 else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def llm_judge_tone_consistency(output: str, expected_tone: str) -> int:\n",
    "    \"\"\"LLM-as-Judge: í†¤ ì¼ì¹˜ë„ í‰ê°€ (0-5ì )\"\"\"\n",
    "    judge_prompt = f\"\"\"ë‹¤ìŒ ë¬¸ì„œì˜ í†¤(tone)ì´ '{expected_tone}' í†¤ê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ 0-5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€:\n",
    "- 5ì : ì™„ë²½í•˜ê²Œ ì¼ì¹˜\n",
    "- 4ì : ëŒ€ë¶€ë¶„ ì¼ì¹˜í•˜ë‚˜ ì¼ë¶€ ë¶ˆì¼ì¹˜\n",
    "- 3ì : ì¤‘ê°„ ì •ë„ ì¼ì¹˜\n",
    "- 2ì : ë§ì´ ë¶ˆì¼ì¹˜\n",
    "- 1ì : ê±°ì˜ ë¶ˆì¼ì¹˜\n",
    "- 0ì : ì™„ì „ ë¶ˆì¼ì¹˜\n",
    "\n",
    "ë¬¸ì„œ:\n",
    "{output}\n",
    "\n",
    "ìˆ«ìë§Œ ë‹µë³€í•˜ì„¸ìš” (0-5):\"\"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": judge_prompt}]\n",
    "    )\n",
    "    \n",
    "    score_text = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        score = int(score_text)\n",
    "        return min(max(score, 0), 5)  # Clamp to 0-5\n",
    "    except:\n",
    "        return 3  # Default to middle score if parsing fails\n",
    "\n",
    "\n",
    "def llm_judge_edit_need(output: str) -> int:\n",
    "    \"\"\"LLM-as-Judge: í¸ì§‘ í•„ìš”ë„ í‰ê°€ (0-5ì , ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\"\"\"\n",
    "    judge_prompt = f\"\"\"ë‹¤ìŒ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œë¥¼ ë°”ë¡œ ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì–¼ë§ˆë‚˜ ë§ì€ í¸ì§‘ì´ í•„ìš”í•œì§€ 0-5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€:\n",
    "- 0ì : í¸ì§‘ ë¶ˆí•„ìš”, ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "- 1ì : ê·¹ì†ŒëŸ‰ì˜ í¸ì§‘ë§Œ í•„ìš”\n",
    "- 2ì : ì¼ë¶€ í¸ì§‘ í•„ìš”\n",
    "- 3ì : ìƒë‹¹í•œ í¸ì§‘ í•„ìš”\n",
    "- 4ì : ëŒ€ë¶€ë¶„ ë‹¤ì‹œ ì‘ì„± í•„ìš”\n",
    "- 5ì : ì™„ì „íˆ ë‹¤ì‹œ ì‘ì„± í•„ìš”\n",
    "\n",
    "ë¬¸ì„œ:\n",
    "{output}\n",
    "\n",
    "ìˆ«ìë§Œ ë‹µë³€í•˜ì„¸ìš” (0-5):\"\"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": judge_prompt}]\n",
    "    )\n",
    "    \n",
    "    score_text = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        score = int(score_text)\n",
    "        return min(max(score, 0), 5)\n",
    "    except:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def evaluate_output(output: str, reference: Dict) -> Dict:\n",
    "    \"\"\"ì „ì²´ í‰ê°€ ì‹¤í–‰\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # ì •ëŸ‰ í‰ê°€\n",
    "    results.update(evaluate_mandatory_items(output, reference.get('must_include', [])))\n",
    "    results.update(evaluate_length(output, reference.get('max_length', 500)))\n",
    "    \n",
    "    # ì •ì„± í‰ê°€ (LLM-as-Judge)\n",
    "    results['tone_consistency_score'] = llm_judge_tone_consistency(\n",
    "        output, reference.get('tone', 'neutral')\n",
    "    )\n",
    "    results['edit_need_score'] = llm_judge_edit_need(output)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Evaluation í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bb307",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ V1 vs V2 í‰ê°€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a7a3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š V1 ê²°ê³¼ í‰ê°€ ì¤‘...\n",
      "============================================================\n",
      "[1/5] Evaluating e001...\n",
      "[2/5] Evaluating e002...\n",
      "[2/5] Evaluating e002...\n",
      "[3/5] Evaluating e003...\n",
      "[3/5] Evaluating e003...\n",
      "[4/5] Evaluating e004...\n",
      "[4/5] Evaluating e004...\n",
      "[5/5] Evaluating e005...\n",
      "[5/5] Evaluating e005...\n",
      "\n",
      "============================================================\n",
      "âœ… V1 í‰ê°€ ì™„ë£Œ\n",
      "\n",
      "V1 í‰ê·  ì„±ëŠ¥:\n",
      "  í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 0.0%\n",
      "  ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨: 100.0%\n",
      "  í†¤ ì¼ì¹˜ë„: 4.80/5\n",
      "  í¸ì§‘ í•„ìš”ë„: 1.20/5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "\n",
      "============================================================\n",
      "âœ… V1 í‰ê°€ ì™„ë£Œ\n",
      "\n",
      "V1 í‰ê·  ì„±ëŠ¥:\n",
      "  í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 0.0%\n",
      "  ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨: 100.0%\n",
      "  í†¤ ì¼ì¹˜ë„: 4.80/5\n",
      "  í¸ì§‘ í•„ìš”ë„: 1.20/5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š V1 ê²°ê³¼ í‰ê°€ ì¤‘...\\n\" + \"=\"*60)\n",
    "\n",
    "v1_eval_results = []\n",
    "for i, result in enumerate(v1_results, 1):\n",
    "    print(f\"[{i}/{len(v1_results)}] Evaluating {result['id']}...\")\n",
    "    eval_result = evaluate_output(result['output'], result['reference'])\n",
    "    v1_eval_results.append(eval_result)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… V1 í‰ê°€ ì™„ë£Œ\\n\")\n",
    "\n",
    "# V1 í‰ê·  ê³„ì‚°\n",
    "v1_avg = {\n",
    "    \"mandatory_items_rate\": sum(r['mandatory_items_rate'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "    \"length_compliant_rate\": sum(r['length_compliant'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "    \"avg_tone_score\": sum(r['tone_consistency_score'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "    \"avg_edit_need\": sum(r['edit_need_score'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "}\n",
    "\n",
    "print(\"V1 í‰ê·  ì„±ëŠ¥:\")\n",
    "print(f\"  í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : {v1_avg['mandatory_items_rate']*100:.1f}%\")\n",
    "print(f\"  ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨: {v1_avg['length_compliant_rate']*100:.1f}%\")\n",
    "print(f\"  í†¤ ì¼ì¹˜ë„: {v1_avg['avg_tone_score']:.2f}/5\")\n",
    "print(f\"  í¸ì§‘ í•„ìš”ë„: {v1_avg['avg_edit_need']:.2f}/5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67bcb5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š V2 ê²°ê³¼ í‰ê°€ ì¤‘...\n",
      "============================================================\n",
      "[1/5] Evaluating e001...\n",
      "[2/5] Evaluating e002...\n",
      "[2/5] Evaluating e002...\n",
      "[3/5] Evaluating e003...\n",
      "[3/5] Evaluating e003...\n",
      "[4/5] Evaluating e004...\n",
      "[4/5] Evaluating e004...\n",
      "[5/5] Evaluating e005...\n",
      "[5/5] Evaluating e005...\n",
      "\n",
      "============================================================\n",
      "âœ… V2 í‰ê°€ ì™„ë£Œ\n",
      "\n",
      "V2 í‰ê·  ì„±ëŠ¥:\n",
      "  í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 53.3%\n",
      "  ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨: 100.0%\n",
      "  í†¤ ì¼ì¹˜ë„: 4.80/5\n",
      "  í¸ì§‘ í•„ìš”ë„: 1.20/5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "\n",
      "============================================================\n",
      "âœ… V2 í‰ê°€ ì™„ë£Œ\n",
      "\n",
      "V2 í‰ê·  ì„±ëŠ¥:\n",
      "  í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 53.3%\n",
      "  ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨: 100.0%\n",
      "  í†¤ ì¼ì¹˜ë„: 4.80/5\n",
      "  í¸ì§‘ í•„ìš”ë„: 1.20/5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š V2 ê²°ê³¼ í‰ê°€ ì¤‘...\\n\" + \"=\"*60)\n",
    "\n",
    "v2_eval_results = []\n",
    "for i, result in enumerate(v2_results, 1):\n",
    "    print(f\"[{i}/{len(v2_results)}] Evaluating {result['id']}...\")\n",
    "    eval_result = evaluate_output(result['output'], result['reference'])\n",
    "    v2_eval_results.append(eval_result)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… V2 í‰ê°€ ì™„ë£Œ\\n\")\n",
    "\n",
    "# V2 í‰ê·  ê³„ì‚°\n",
    "v2_avg = {\n",
    "    \"mandatory_items_rate\": sum(r['mandatory_items_rate'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "    \"length_compliant_rate\": sum(r['length_compliant'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "    \"avg_tone_score\": sum(r['tone_consistency_score'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "    \"avg_edit_need\": sum(r['edit_need_score'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "}\n",
    "\n",
    "print(\"V2 í‰ê·  ì„±ëŠ¥:\")\n",
    "print(f\"  í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : {v2_avg['mandatory_items_rate']*100:.1f}%\")\n",
    "print(f\"  ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨: {v2_avg['length_compliant_rate']*100:.1f}%\")\n",
    "print(f\"  í†¤ ì¼ì¹˜ë„: {v2_avg['avg_tone_score']:.2f}/5\")\n",
    "print(f\"  í¸ì§‘ í•„ìš”ë„: {v2_avg['avg_edit_need']:.2f}/5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e27fa",
   "metadata": {},
   "source": [
    "## ğŸ“‹ V1 vs V2 ë¹„êµ ë¦¬í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c15e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š V1 vs V2 ì„±ëŠ¥ ë¹„êµí‘œ\n",
      "================================================================================\n",
      "                   ì§€í‘œ V1 (dev) V2 (production)     ê°œì„ ë„\n",
      "        í•„ìˆ˜ í•­ëª© í¬í•¨ë¥  (%)     0.0%           53.3% +53.3%p\n",
      "        ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨ (%)   100.0%          100.0%  +0.0%p\n",
      "          í†¤ ì¼ì¹˜ë„ (0-5)     4.80            4.80   +0.00\n",
      "í¸ì§‘ í•„ìš”ë„ (0-5, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)     1.20            1.20   +0.00\n",
      "================================================================================\n",
      "\n",
      "âœ… ë¹„êµí‘œ ì €ì¥: v1_vs_v2_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë¹„êµí‘œ ìƒì„±\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"ì§€í‘œ\": [\n",
    "        \"í•„ìˆ˜ í•­ëª© í¬í•¨ë¥  (%)\",\n",
    "        \"ê¸¸ì´ ì œí•œ ì¤€ìˆ˜ìœ¨ (%)\",\n",
    "        \"í†¤ ì¼ì¹˜ë„ (0-5)\",\n",
    "        \"í¸ì§‘ í•„ìš”ë„ (0-5, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\"\n",
    "    ],\n",
    "    \"V1 (dev)\": [\n",
    "        f\"{v1_avg['mandatory_items_rate']*100:.1f}%\",\n",
    "        f\"{v1_avg['length_compliant_rate']*100:.1f}%\",\n",
    "        f\"{v1_avg['avg_tone_score']:.2f}\",\n",
    "        f\"{v1_avg['avg_edit_need']:.2f}\"\n",
    "    ],\n",
    "    \"V2 (production)\": [\n",
    "        f\"{v2_avg['mandatory_items_rate']*100:.1f}%\",\n",
    "        f\"{v2_avg['length_compliant_rate']*100:.1f}%\",\n",
    "        f\"{v2_avg['avg_tone_score']:.2f}\",\n",
    "        f\"{v2_avg['avg_edit_need']:.2f}\"\n",
    "    ],\n",
    "    \"ê°œì„ ë„\": [\n",
    "        f\"{(v2_avg['mandatory_items_rate'] - v1_avg['mandatory_items_rate'])*100:+.1f}%p\",\n",
    "        f\"{(v2_avg['length_compliant_rate'] - v1_avg['length_compliant_rate'])*100:+.1f}%p\",\n",
    "        f\"{v2_avg['avg_tone_score'] - v1_avg['avg_tone_score']:+.2f}\",\n",
    "        f\"{v2_avg['avg_edit_need'] - v1_avg['avg_edit_need']:+.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š V1 vs V2 ì„±ëŠ¥ ë¹„êµí‘œ\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "comparison_df.to_csv(\"v1_vs_v2_comparison.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"\\nâœ… ë¹„êµí‘œ ì €ì¥: v1_vs_v2_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41d02e",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì£¼ìš” ë°œê²¬ì‚¬í•­ ë° ê°œì„ ì•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b145dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” V1 ì£¼ìš” ì‹¤íŒ¨ ì‚¬ë¡€ (Top 3)\n",
      "============================================================\n",
      "\n",
      "1. ID: e003\n",
      "   í¸ì§‘ í•„ìš”ë„: 2/5\n",
      "   í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 0%\n",
      "   ë¬¸ì œì : êµ¬ì¡°í™” ë¶€ì¡±, í•„ìˆ˜ ìš”ì†Œ ëˆ„ë½, í†¤ ë¶ˆì¼ì¹˜\n",
      "\n",
      "2. ID: e001\n",
      "   í¸ì§‘ í•„ìš”ë„: 1/5\n",
      "   í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 0%\n",
      "   ë¬¸ì œì : êµ¬ì¡°í™” ë¶€ì¡±, í•„ìˆ˜ ìš”ì†Œ ëˆ„ë½, í†¤ ë¶ˆì¼ì¹˜\n",
      "\n",
      "3. ID: e002\n",
      "   í¸ì§‘ í•„ìš”ë„: 1/5\n",
      "   í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : 0%\n",
      "   ë¬¸ì œì : êµ¬ì¡°í™” ë¶€ì¡±, í•„ìˆ˜ ìš”ì†Œ ëˆ„ë½, í†¤ ë¶ˆì¼ì¹˜\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ’¡ ë‹¤ìŒ ê°œì„ ì•ˆ (V3 ê³ ë ¤ì‚¬í•­)\n",
      "============================================================\n",
      "1. Few-shot examples ì¶”ê°€í•˜ì—¬ í˜•ì‹ ì¼ê´€ì„± í–¥ìƒ\n",
      "2. JSON Schemaë¡œ ì¶œë ¥ êµ¬ì¡°í™” ê°•ì œ\n",
      "3. Chain-of-Thoughtë¡œ í•„ìˆ˜ í•­ëª© ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¨¼ì € ì‘ì„±\n",
      "4. ì—…ì¢…ë³„/ëª©ì ë³„ í”„ë¡¬í”„íŠ¸ ì„¸ë¶„í™” (ì´ë©”ì¼ vs ë³´ê³ ì„œ vs ì œì•ˆì„œ)\n",
      "5. Self-critique ë‹¨ê³„ ì¶”ê°€ (ìƒì„± í›„ ìê¸° ê²€ì¦)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„ (V1ì—ì„œ ì ìˆ˜ê°€ ë‚®ì•˜ë˜ ì¼€ì´ìŠ¤)\n",
    "print(\"ğŸ” V1 ì£¼ìš” ì‹¤íŒ¨ ì‚¬ë¡€ (Top 3)\\n\" + \"=\"*60)\n",
    "\n",
    "# Edit needê°€ ê°€ì¥ ë†’ì€ 3ê°œ ì°¾ê¸°\n",
    "v1_with_scores = [(i, r) for i, r in enumerate(v1_eval_results)]\n",
    "v1_worst = sorted(v1_with_scores, key=lambda x: x[1]['edit_need_score'], reverse=True)[:3]\n",
    "\n",
    "for rank, (idx, eval_result) in enumerate(v1_worst, 1):\n",
    "    print(f\"\\n{rank}. ID: {v1_results[idx]['id']}\")\n",
    "    print(f\"   í¸ì§‘ í•„ìš”ë„: {eval_result['edit_need_score']}/5\")\n",
    "    print(f\"   í•„ìˆ˜ í•­ëª© í¬í•¨ë¥ : {eval_result['mandatory_items_rate']*100:.0f}%\")\n",
    "    print(f\"   ë¬¸ì œì : êµ¬ì¡°í™” ë¶€ì¡±, í•„ìˆ˜ ìš”ì†Œ ëˆ„ë½, í†¤ ë¶ˆì¼ì¹˜\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nğŸ’¡ ë‹¤ìŒ ê°œì„ ì•ˆ (V3 ê³ ë ¤ì‚¬í•­)\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Few-shot examples ì¶”ê°€í•˜ì—¬ í˜•ì‹ ì¼ê´€ì„± í–¥ìƒ\")\n",
    "print(\"2. JSON Schemaë¡œ ì¶œë ¥ êµ¬ì¡°í™” ê°•ì œ\")\n",
    "print(\"3. Chain-of-Thoughtë¡œ í•„ìˆ˜ í•­ëª© ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¨¼ì € ì‘ì„±\")\n",
    "print(\"4. ì—…ì¢…ë³„/ëª©ì ë³„ í”„ë¡¬í”„íŠ¸ ì„¸ë¶„í™” (ì´ë©”ì¼ vs ë³´ê³ ì„œ vs ì œì•ˆì„œ)\")\n",
    "print(\"5. Self-critique ë‹¨ê³„ ì¶”ê°€ (ìƒì„± í›„ ìê¸° ê²€ì¦)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
