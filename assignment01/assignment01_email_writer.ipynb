{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee5c5ac",
   "metadata": {},
   "source": [
    "# Assignment 01 — Email & Document Writer with Langfuse\n",
    "\n",
    "## 🎯 프로젝트 개요\n",
    "**주제**: 이메일·문서 자동 작성  \n",
    "**목적**: Prompt 버전 관리 → 배포 → Tracing → Evaluation 전체 사이클 구현\n",
    "\n",
    "### 평가 지표\n",
    "1. **형식 준수율** (Schema Compliance): 필수 구조 요소 포함 여부\n",
    "2. **필수 항목 포함률** (Mandatory Items): must_include 리스트 완성도\n",
    "3. **톤 일치도** (Tone Consistency): LLM-as-Judge로 0-5점 평가\n",
    "4. **길이 제한 준수** (Length Control): max_length 이내 작성 여부\n",
    "5. **편집 필요도** (Edit Need): LLM-as-Judge로 0-5점 평가 (낮을수록 좋음)\n",
    "\n",
    "### 버전 비교\n",
    "- **V1.0.0 (dev)**: 기본 프롬프트 - 간단한 입력만 받음\n",
    "- **V2.0.0 (production)**: 개선 프롬프트 - 상세 제약조건, 필수 요소 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683a223",
   "metadata": {},
   "source": [
    "## 📦 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78979a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse[all] in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (3.6.1)\n",
      "\u001b[33mWARNING: langfuse 3.6.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: backoff>=1.10.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (2.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse[all]) (1.17.2)\n",
      "Requirement already satisfied: anyio in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse[all]) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse[all]) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse[all]) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse[all]) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse[all]) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse[all]) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse[all]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse[all]) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2->langfuse[all]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2->langfuse[all]) (2.2.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse[all]) (3.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from anyio->httpx<1.0,>=0.15.4->langfuse[all]) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langfuse openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1ef04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment Check:\n",
      "  Langfuse Host: https://cloud.langfuse.com\n",
      "  Langfuse Public Key: ✓\n",
      "  Langfuse Secret Key: ✓\n",
      "  OpenAI API Key: ✓\n",
      "\n",
      "✅ Langfuse 연결 성공!\n",
      "\n",
      "✅ Langfuse 연결 성공!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 설정\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✅ Environment Check:\")\n",
    "print(f\"  Langfuse Host: {LANGFUSE_HOST}\")\n",
    "print(f\"  Langfuse Public Key: {'✓' if LANGFUSE_PUBLIC_KEY else '✗'}\")\n",
    "print(f\"  Langfuse Secret Key: {'✓' if LANGFUSE_SECRET_KEY else '✗'}\")\n",
    "print(f\"  OpenAI API Key: {'✓' if OPENAI_API_KEY else '✗'}\")\n",
    "\n",
    "# Langfuse 초기화\n",
    "langfuse = Langfuse(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# OpenAI 클라이언트 초기화 (Langfuse wrapper 사용)\n",
    "from langfuse.openai import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "print(\"\\n✅ Langfuse 연결 성공!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086be95",
   "metadata": {},
   "source": [
    "## 📊 Dataset 로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5d3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 로드 완료: 15개 샘플\n",
      "\n",
      "샘플 #1:\n",
      "{\n",
      "  \"id\": \"e001\",\n",
      "  \"input\": {\n",
      "    \"purpose\": \"출장 보고서\",\n",
      "    \"audience\": \"임원진\",\n",
      "    \"key_points\": [\n",
      "      \"예산 집행 현황\",\n",
      "      \"주요 미팅 결과\",\n",
      "      \"리스크 요인\"\n",
      "    ]\n",
      "  },\n",
      "  \"reference\": {\n",
      "    \"style\": \"formal\",\n",
      "    \"must_include\": [\n",
      "      \"예산 수치\",\n",
      "      \"리스크 2개 이상\",\n",
      "      \"향후 조치사항\"\n",
      "    ],\n",
      "    \"tone\": \"professional\",\n",
      "    \"max_length\": 500\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# JSONL 데이터셋 로드\n",
    "dataset_path = Path(\"datasets/email_writer_eval.jsonl\")\n",
    "\n",
    "def load_dataset(path: Path) -> List[Dict]:\n",
    "    \"\"\"JSONL 파일 로드\"\"\"\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "dataset = load_dataset(dataset_path)\n",
    "print(f\"✅ 데이터셋 로드 완료: {len(dataset)}개 샘플\")\n",
    "print(f\"\\n샘플 #1:\")\n",
    "print(json.dumps(dataset[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0adb46",
   "metadata": {},
   "source": [
    "## 🔧 Prompt 버전 로드 (V1 & V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995cbc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ V1 Prompt 로드 완료\n",
      "  System: 132 chars\n",
      "  User Template: 204 chars\n",
      "\n",
      "✅ V2 Prompt 로드 완료\n",
      "  System: 873 chars\n",
      "  User Template: 647 chars\n"
     ]
    }
   ],
   "source": [
    "# .prompty 파일 파싱 함수\n",
    "def parse_prompty_file(path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"Parse .prompty file and extract metadata + prompt\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split frontmatter and prompt content\n",
    "    parts = content.split('---')\n",
    "    if len(parts) >= 3:\n",
    "        # frontmatter = parts[1]  # YAML metadata (not parsing for now)\n",
    "        prompt_content = parts[2].strip()\n",
    "    else:\n",
    "        prompt_content = content\n",
    "    \n",
    "    # Extract system and user sections\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    \n",
    "    if \"system:\" in prompt_content:\n",
    "        parts = prompt_content.split(\"user:\", 1)\n",
    "        system_prompt = parts[0].replace(\"system:\", \"\").strip()\n",
    "        if len(parts) > 1:\n",
    "            user_prompt = parts[1].strip()\n",
    "    else:\n",
    "        user_prompt = prompt_content.strip()\n",
    "    \n",
    "    return {\n",
    "        \"system\": system_prompt,\n",
    "        \"user_template\": user_prompt\n",
    "    }\n",
    "\n",
    "# V1, V2 프롬프트 로드\n",
    "prompt_v1 = parse_prompty_file(Path(\"prompts/email_writer_v1.0.prompty\"))\n",
    "prompt_v2 = parse_prompty_file(Path(\"prompts/email_writer_v2.0.prompty\"))\n",
    "\n",
    "print(\"✅ V1 Prompt 로드 완료\")\n",
    "print(f\"  System: {len(prompt_v1['system'])} chars\")\n",
    "print(f\"  User Template: {len(prompt_v1['user_template'])} chars\")\n",
    "print(\"\\n✅ V2 Prompt 로드 완료\")\n",
    "print(f\"  System: {len(prompt_v2['system'])} chars\")\n",
    "print(f\"  User Template: {len(prompt_v2['user_template'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad9c7f",
   "metadata": {},
   "source": [
    "## 🚀 Langfuse에 Prompt 배포 (Versioning)\n",
    "\n",
    "**중요**: Langfuse UI에서 수동으로 Prompt를 생성한 후, 여기서 fetch하여 사용합니다.  \n",
    "또는 API로 직접 생성할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724304fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ V1 Prompt 배포 완료 (dev label)\n",
      "✅ V2 Prompt 배포 완료 (production label)\n",
      "✅ V2 Prompt 배포 완료 (production label)\n",
      "\n",
      "🔄 Langfuse에 Prompt 동기화 완료\n",
      "\n",
      "🔄 Langfuse에 Prompt 동기화 완료\n"
     ]
    }
   ],
   "source": [
    "# Langfuse에 Prompt 생성/업데이트\n",
    "# 참고: Langfuse Python SDK에서는 create_prompt() 메서드 사용\n",
    "\n",
    "PROMPT_NAME = \"email-writer\"\n",
    "\n",
    "# V1 배포 (dev 라벨)\n",
    "try:\n",
    "    langfuse.create_prompt(\n",
    "        name=PROMPT_NAME,\n",
    "        prompt=prompt_v1['user_template'],\n",
    "        config={\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 800,\n",
    "            \"system_message\": prompt_v1['system']\n",
    "        },\n",
    "        labels=[\"dev\"],\n",
    "        tags=[\"v1.0.0\", \"basic\", \"email-writing\"]\n",
    "    )\n",
    "    print(\"✅ V1 Prompt 배포 완료 (dev label)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  V1 Prompt 이미 존재하거나 오류: {e}\")\n",
    "\n",
    "# V2 배포 (production 라벨)\n",
    "try:\n",
    "    langfuse.create_prompt(\n",
    "        name=PROMPT_NAME,\n",
    "        prompt=prompt_v2['user_template'],\n",
    "        config={\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"system_message\": prompt_v2['system']\n",
    "        },\n",
    "        labels=[\"production\"],\n",
    "        tags=[\"v2.0.0\", \"professional\", \"email-writing\", \"structured\"]\n",
    "    )\n",
    "    print(\"✅ V2 Prompt 배포 완료 (production label)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  V2 Prompt 이미 존재하거나 오류: {e}\")\n",
    "\n",
    "# Flush to ensure prompts are created\n",
    "langfuse.flush()\n",
    "time.sleep(2)\n",
    "print(\"\\n🔄 Langfuse에 Prompt 동기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83bcf4",
   "metadata": {},
   "source": [
    "## 📝 Email 생성 함수 (with Tracing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca305a9",
   "metadata": {},
   "source": [
    "Summarized conversation history선택하신 코드는 **Langfuse에 Prompt를 프로그래밍 방식으로 배포(생성)하는 코드**입니다. 각 부분을 설명드리겠습니다:\n",
    "\n",
    "## 🎯 코드의 목적\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langfuse.create_prompt(\n",
    "#     name=\"email-writer\",\n",
    "#     prompt=prompt_v1['user_template'],\n",
    "#     config={...},\n",
    "#     labels=[\"dev\"],\n",
    "#     tags=[\"v1.0.0\", \"basic\", \"email-writing\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558c2e7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "이 코드는 **Langfuse 플랫폼에 프롬프트를 등록**하여:\n",
    "1. **버전 관리**: 프롬프트를 중앙에서 관리하고 버전을 추적\n",
    "2. **재사용성**: 여러 곳에서 같은 프롬프트를 fetch하여 사용\n",
    "3. **라벨링**: `dev`와 `production` 환경 구분\n",
    "4. **추적**: 어떤 프롬프트 버전이 어떤 결과를 냈는지 추적 가능\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 파라미터 설명\n",
    "\n",
    "### 1. `name=\"email-writer\"`\n",
    "- **프롬프트 식별자**: Langfuse에서 이 프롬프트를 찾을 때 사용하는 이름\n",
    "- 나중에 `langfuse.get_prompt(\"email-writer\", label=\"dev\")`로 불러올 수 있음\n",
    "\n",
    "### 2. `prompt=prompt_v1['user_template']`\n",
    "- **실제 프롬프트 텍스트**: `.prompty` 파일에서 파싱한 사용자 메시지 템플릿\n",
    "- Jinja2 형식의 템플릿 문자열 (예: `{{purpose}}`, `{{key_points}}`)\n",
    "\n",
    "### 3. `config={...}`\n",
    "- **모델 설정**: OpenAI 호출 시 사용할 파라미터들\n",
    "  ```python\n",
    "  {\n",
    "      \"model\": \"gpt-4o-mini\",        # 사용할 모델\n",
    "      \"temperature\": 0.7,             # 창의성 정도 (0-1)\n",
    "      \"max_tokens\": 800,              # 최대 출력 길이\n",
    "      \"system_message\": prompt_v1['system']  # 시스템 프롬프트\n",
    "  }\n",
    "  ```\n",
    "\n",
    "### 4. `labels=[\"dev\"]` (V1) / `[\"production\"]` (V2)\n",
    "- **환경 라벨**: 개발/운영 환경 구분\n",
    "  - `dev`: 테스트 중인 버전 (V1)\n",
    "  - `production`: 실제 사용 중인 버전 (V2)\n",
    "- 같은 이름의 프롬프트를 여러 버전으로 관리 가능\n",
    "\n",
    "### 5. `tags=[\"v1.0.0\", \"basic\", \"email-writing\"]`\n",
    "- **메타데이터 태그**: 검색, 분류, 필터링 용도\n",
    "  - 버전 번호: `v1.0.0`, `v2.0.0`\n",
    "  - 특징: `basic`, `professional`, `structured`\n",
    "  - 카테고리: `email-writing`\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 V1 vs V2 비교\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # V1 (개발 버전)\n",
    "# langfuse.create_prompt(\n",
    "#     name=\"email-writer\",\n",
    "#     labels=[\"dev\"],           # 개발 환경\n",
    "#     tags=[\"v1.0.0\", \"basic\"], # 기본 버전\n",
    "#     config={\"max_tokens\": 800}\n",
    "# )\n",
    "\n",
    "# # V2 (프로덕션 버전)\n",
    "# langfuse.create_prompt(\n",
    "#     name=\"email-writer\",\n",
    "#     labels=[\"production\"],          # 운영 환경\n",
    "#     tags=[\"v2.0.0\", \"professional\"], # 개선 버전\n",
    "#     config={\"max_tokens\": 1000}     # 더 긴 출력 허용\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11985c81",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "두 버전 모두 **같은 이름** (`email-writer`)이지만, **다른 라벨**로 구분됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 실제 사용 예시\n",
    "\n",
    "1. **프롬프트 등록** (지금 실행하는 셀)\n",
    "   ```python\n",
    "   langfuse.create_prompt(name=\"email-writer\", labels=[\"dev\"], ...)\n",
    "   ```\n",
    "\n",
    "2. **나중에 불러오기**\n",
    "   ```python\n",
    "   # 개발 버전 사용\n",
    "   prompt = langfuse.get_prompt(\"email-writer\", label=\"dev\")\n",
    "   \n",
    "   # 운영 버전 사용\n",
    "   prompt = langfuse.get_prompt(\"email-writer\", label=\"production\")\n",
    "   ```\n",
    "\n",
    "3. **Langfuse UI에서 확인**\n",
    "   - 웹 대시보드에서 프롬프트 히스토리 조회\n",
    "   - 어떤 버전이 언제 배포되었는지 추적\n",
    "   - A/B 테스트 결과 비교\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 주의사항\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# except Exception as e:\n",
    "#     print(f\"⚠️  V1 Prompt 이미 존재하거나 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac112a19",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **중복 방지**: 같은 이름+라벨로 이미 프롬프트가 있으면 오류 발생\n",
    "- 재실행 시 오류 무시하고 계속 진행\n",
    "\n",
    "---\n",
    "\n",
    "**요약**: 이 코드는 `.prompty` 파일의 내용을 Langfuse 클라우드에 업로드하여 **중앙 집중식 프롬프트 버전 관리**를 시작하는 코드입니다. 마치 Git에 코드를 push하는 것처럼, 프롬프트를 Langfuse에 \"배포\"하는 것이죠! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a415b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Email 생성 함수 정의 완료 (Tracing 활성화)\n"
     ]
    }
   ],
   "source": [
    "def generate_email_v1(\n",
    "    purpose: str,\n",
    "    audience: str,\n",
    "    key_points: List[str],\n",
    "    trace_name: str = \"email-generation-v1\"\n",
    ") -> str:\n",
    "    \"\"\"V1 프롬프트로 이메일 생성 (Langfuse Tracing)\"\"\"\n",
    "    \n",
    "    # User prompt 구성\n",
    "    key_points_text = \"\\n\".join([f\"- {point}\" for point in key_points])\n",
    "    user_message = f\"\"\"Write a {purpose} for {audience}.\n",
    "\n",
    "Key points to include:\n",
    "{key_points_text}\n",
    "\n",
    "Please write a professional document that covers all key points clearly and concisely.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_v1['system']},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # OpenAI API 호출 with Langfuse tracing (자동)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages,\n",
    "        # Langfuse metadata\n",
    "        name=trace_name,\n",
    "        metadata={\n",
    "            \"purpose\": purpose,\n",
    "            \"audience\": audience,\n",
    "            \"key_points_count\": len(key_points),\n",
    "            \"version\": \"v1.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def generate_email_v2(\n",
    "    purpose: str,\n",
    "    audience: str,\n",
    "    key_points: List[str],\n",
    "    style: str = \"professional\",\n",
    "    tone: str = \"neutral\",\n",
    "    must_include: List[str] = None,\n",
    "    max_length: int = 500,\n",
    "    trace_name: str = \"email-generation-v2\"\n",
    ") -> str:\n",
    "    \"\"\"V2 프롬프트로 이메일 생성 (Langfuse Tracing)\"\"\"\n",
    "    \n",
    "    if must_include is None:\n",
    "        must_include = []\n",
    "    \n",
    "    # User prompt 구성 (V2 템플릿)\n",
    "    key_points_text = \"\\n\".join([f\"- {point}\" for point in key_points])\n",
    "    must_include_text = \"\\n\".join([f\"✓ {item}\" for item in must_include])\n",
    "    \n",
    "    user_message = f\"\"\"**Document Type:** {purpose}\n",
    "**Target Audience:** {audience}\n",
    "\n",
    "**Key Points to Address:**\n",
    "{key_points_text}\n",
    "\n",
    "**Writing Requirements:**\n",
    "- Style: {style}\n",
    "- Tone: {tone}\n",
    "- Maximum Length: {max_length} words\n",
    "\n",
    "**Mandatory Elements (MUST INCLUDE ALL):**\n",
    "{must_include_text}\n",
    "\n",
    "Please generate a professional document that:\n",
    "1. Addresses all key points comprehensively\n",
    "2. Includes ALL mandatory elements listed above\n",
    "3. Maintains the specified style and tone consistently\n",
    "4. Stays within the word limit\n",
    "5. Follows proper business document structure\n",
    "\n",
    "Generate the document now:\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_v2['system']},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # OpenAI API 호출 with Langfuse tracing (자동)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        messages=messages,\n",
    "        # Langfuse metadata\n",
    "        name=trace_name,\n",
    "        metadata={\n",
    "            \"purpose\": purpose,\n",
    "            \"audience\": audience,\n",
    "            \"key_points_count\": len(key_points),\n",
    "            \"style\": style,\n",
    "            \"tone\": tone,\n",
    "            \"must_include_count\": len(must_include),\n",
    "            \"max_length\": max_length,\n",
    "            \"version\": \"v2.0.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"✅ Email 생성 함수 정의 완료 (Tracing 활성화)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c24958",
   "metadata": {},
   "source": [
    "## 🧪 V1 & V2 테스트 실행 (최소 5건씩 Trace 남기기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d3b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 V1 Prompt 테스트 (5건)\n",
      "============================================================\n",
      "\n",
      "[1/5] 출장 보고서...\n",
      "  ✅ 생성 완료 (1170 chars)\n",
      "  ✅ 생성 완료 (1170 chars)\n",
      "\n",
      "[2/5] 프로젝트 제안서...\n",
      "\n",
      "[2/5] 프로젝트 제안서...\n",
      "  ✅ 생성 완료 (1196 chars)\n",
      "  ✅ 생성 완료 (1196 chars)\n",
      "\n",
      "[3/5] 고객 불만 응대 이메일...\n",
      "\n",
      "[3/5] 고객 불만 응대 이메일...\n",
      "  ✅ 생성 완료 (650 chars)\n",
      "  ✅ 생성 완료 (650 chars)\n",
      "\n",
      "[4/5] 팀원 업무 지시...\n",
      "\n",
      "[4/5] 팀원 업무 지시...\n",
      "  ✅ 생성 완료 (427 chars)\n",
      "  ✅ 생성 완료 (427 chars)\n",
      "\n",
      "[5/5] 협업 제안 이메일...\n",
      "\n",
      "[5/5] 협업 제안 이메일...\n",
      "  ✅ 생성 완료 (440 chars)\n",
      "  ✅ 생성 완료 (440 chars)\n",
      "\n",
      "============================================================\n",
      "✅ V1 테스트 완료! Langfuse에서 Trace 확인 가능\n",
      "\n",
      "============================================================\n",
      "✅ V1 테스트 완료! Langfuse에서 Trace 확인 가능\n"
     ]
    }
   ],
   "source": [
    "# V1 테스트: 처음 5개 샘플로 실행\n",
    "print(\"🔍 V1 Prompt 테스트 (5건)\\n\" + \"=\"*60)\n",
    "\n",
    "v1_results = []\n",
    "for i, sample in enumerate(dataset[:5], 1):\n",
    "    print(f\"\\n[{i}/5] {sample['input']['purpose']}...\")\n",
    "    \n",
    "    output = generate_email_v1(\n",
    "        purpose=sample['input']['purpose'],\n",
    "        audience=sample['input']['audience'],\n",
    "        key_points=sample['input']['key_points'],\n",
    "        trace_name=f\"v1-test-{sample['id']}\"\n",
    "    )\n",
    "    \n",
    "    v1_results.append({\n",
    "        \"id\": sample['id'],\n",
    "        \"output\": output,\n",
    "        \"reference\": sample['reference']\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✅ 생성 완료 ({len(output)} chars)\")\n",
    "    time.sleep(0.5)  # Rate limit 방지\n",
    "\n",
    "langfuse.flush()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ V1 테스트 완료! Langfuse에서 Trace 확인 가능\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978ea5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 V2 Prompt 테스트 (5건)\n",
      "============================================================\n",
      "\n",
      "[1/5] 출장 보고서...\n",
      "  ✅ 생성 완료 (1221 chars)\n",
      "  ✅ 생성 완료 (1221 chars)\n",
      "\n",
      "[2/5] 프로젝트 제안서...\n",
      "\n",
      "[2/5] 프로젝트 제안서...\n",
      "  ✅ 생성 완료 (1478 chars)\n",
      "  ✅ 생성 완료 (1478 chars)\n",
      "\n",
      "[3/5] 고객 불만 응대 이메일...\n",
      "\n",
      "[3/5] 고객 불만 응대 이메일...\n",
      "  ✅ 생성 완료 (771 chars)\n",
      "  ✅ 생성 완료 (771 chars)\n",
      "\n",
      "[4/5] 팀원 업무 지시...\n",
      "\n",
      "[4/5] 팀원 업무 지시...\n",
      "  ✅ 생성 완료 (609 chars)\n",
      "  ✅ 생성 완료 (609 chars)\n",
      "\n",
      "[5/5] 협업 제안 이메일...\n",
      "\n",
      "[5/5] 협업 제안 이메일...\n",
      "  ✅ 생성 완료 (841 chars)\n",
      "  ✅ 생성 완료 (841 chars)\n",
      "\n",
      "============================================================\n",
      "✅ V2 테스트 완료! Langfuse에서 Trace 확인 가능\n",
      "\n",
      "============================================================\n",
      "✅ V2 테스트 완료! Langfuse에서 Trace 확인 가능\n"
     ]
    }
   ],
   "source": [
    "# V2 테스트: 동일한 5개 샘플로 실행 (비교를 위해)\n",
    "print(\"🔍 V2 Prompt 테스트 (5건)\\n\" + \"=\"*60)\n",
    "\n",
    "v2_results = []\n",
    "for i, sample in enumerate(dataset[:5], 1):\n",
    "    print(f\"\\n[{i}/5] {sample['input']['purpose']}...\")\n",
    "    \n",
    "    output = generate_email_v2(\n",
    "        purpose=sample['input']['purpose'],\n",
    "        audience=sample['input']['audience'],\n",
    "        key_points=sample['input']['key_points'],\n",
    "        style=sample['reference'].get('style', 'professional'),\n",
    "        tone=sample['reference'].get('tone', 'neutral'),\n",
    "        must_include=sample['reference'].get('must_include', []),\n",
    "        max_length=sample['reference'].get('max_length', 500),\n",
    "        trace_name=f\"v2-test-{sample['id']}\"\n",
    "    )\n",
    "    \n",
    "    v2_results.append({\n",
    "        \"id\": sample['id'],\n",
    "        \"output\": output,\n",
    "        \"reference\": sample['reference']\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✅ 생성 완료 ({len(output)} chars)\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "langfuse.flush()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ V2 테스트 완료! Langfuse에서 Trace 확인 가능\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385cec3f",
   "metadata": {},
   "source": [
    "## 📤 Langfuse Dataset에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871a7f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 Langfuse Dataset 'email-writer-eval' 생성 및 업로드 중...\n",
      "\n",
      "✅ Dataset 'email-writer-eval' 생성 완료\n",
      "\n",
      "📝 Dataset 아이템 추가 중...\n",
      "✅ Dataset 'email-writer-eval' 생성 완료\n",
      "\n",
      "📝 Dataset 아이템 추가 중...\n",
      "  진행률: 5/15\n",
      "  진행률: 5/15\n",
      "  진행률: 10/15\n",
      "  진행률: 10/15\n",
      "  진행률: 15/15\n",
      "\n",
      "✅ Dataset 업로드 완료: 15개 아이템\n",
      "   Langfuse UI에서 'email-writer-eval' 확인 가능\n",
      "  진행률: 15/15\n",
      "\n",
      "✅ Dataset 업로드 완료: 15개 아이템\n",
      "   Langfuse UI에서 'email-writer-eval' 확인 가능\n"
     ]
    }
   ],
   "source": [
    "# Langfuse Dataset 생성/업데이트\n",
    "DATASET_NAME = \"email-writer-eval\"\n",
    "\n",
    "print(f\"📤 Langfuse Dataset '{DATASET_NAME}' 생성 및 업로드 중...\\n\")\n",
    "\n",
    "# Step 1: Dataset 먼저 생성\n",
    "try:\n",
    "    langfuse.create_dataset(\n",
    "        name=DATASET_NAME,\n",
    "        description=\"Email & Document Writer 평가용 데이터셋 - 15개 샘플\",\n",
    "        metadata={\n",
    "            \"version\": \"1.0\",\n",
    "            \"created_date\": datetime.now().isoformat(),\n",
    "            \"total_samples\": len(dataset)\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Dataset '{DATASET_NAME}' 생성 완료\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Dataset 이미 존재하거나 오류: {e}\\n\")\n",
    "\n",
    "# Step 2: Dataset에 아이템 추가\n",
    "print(\"📝 Dataset 아이템 추가 중...\")\n",
    "for i, sample in enumerate(dataset, 1):\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=DATASET_NAME,\n",
    "        input=sample['input'],\n",
    "        expected_output=sample['reference'],\n",
    "        metadata={\n",
    "            \"id\": sample['id'],\n",
    "            \"purpose\": sample['input']['purpose']\n",
    "        }\n",
    "    )\n",
    "    if i % 5 == 0:\n",
    "        print(f\"  진행률: {i}/{len(dataset)}\")\n",
    "\n",
    "langfuse.flush()\n",
    "print(f\"\\n✅ Dataset 업로드 완료: {len(dataset)}개 아이템\")\n",
    "print(f\"   Langfuse UI에서 '{DATASET_NAME}' 확인 가능\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6065653",
   "metadata": {},
   "source": [
    "## 📊 Evaluation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb29b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mandatory_items(output: str, must_include: List[str]) -> Dict:\n",
    "    \"\"\"필수 항목 포함 여부 체크 (정량)\"\"\"\n",
    "    found_count = sum(1 for item in must_include if item.lower() in output.lower())\n",
    "    total = len(must_include)\n",
    "    \n",
    "    return {\n",
    "        \"mandatory_items_found\": found_count,\n",
    "        \"mandatory_items_total\": total,\n",
    "        \"mandatory_items_rate\": found_count / total if total > 0 else 1.0\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_length(output: str, max_length: int) -> Dict:\n",
    "    \"\"\"길이 제한 준수 체크 (정량)\"\"\"\n",
    "    word_count = len(output.split())\n",
    "    compliant = word_count <= max_length\n",
    "    \n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"max_length\": max_length,\n",
    "        \"length_compliant\": compliant,\n",
    "        \"length_ratio\": word_count / max_length if max_length > 0 else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def llm_judge_tone_consistency(output: str, expected_tone: str) -> int:\n",
    "    \"\"\"LLM-as-Judge: 톤 일치도 평가 (0-5점)\"\"\"\n",
    "    judge_prompt = f\"\"\"다음 문서의 톤(tone)이 '{expected_tone}' 톤과 얼마나 일치하는지 0-5점으로 평가하세요.\n",
    "\n",
    "평가 기준:\n",
    "- 5점: 완벽하게 일치\n",
    "- 4점: 대부분 일치하나 일부 불일치\n",
    "- 3점: 중간 정도 일치\n",
    "- 2점: 많이 불일치\n",
    "- 1점: 거의 불일치\n",
    "- 0점: 완전 불일치\n",
    "\n",
    "문서:\n",
    "{output}\n",
    "\n",
    "숫자만 답변하세요 (0-5):\"\"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": judge_prompt}]\n",
    "    )\n",
    "    \n",
    "    score_text = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        score = int(score_text)\n",
    "        return min(max(score, 0), 5)  # Clamp to 0-5\n",
    "    except:\n",
    "        return 3  # Default to middle score if parsing fails\n",
    "\n",
    "\n",
    "def llm_judge_edit_need(output: str) -> int:\n",
    "    \"\"\"LLM-as-Judge: 편집 필요도 평가 (0-5점, 낮을수록 좋음)\"\"\"\n",
    "    judge_prompt = f\"\"\"다음 비즈니스 문서를 바로 실무에서 사용하기 위해 얼마나 많은 편집이 필요한지 0-5점으로 평가하세요.\n",
    "\n",
    "평가 기준:\n",
    "- 0점: 편집 불필요, 바로 사용 가능\n",
    "- 1점: 극소량의 편집만 필요\n",
    "- 2점: 일부 편집 필요\n",
    "- 3점: 상당한 편집 필요\n",
    "- 4점: 대부분 다시 작성 필요\n",
    "- 5점: 완전히 다시 작성 필요\n",
    "\n",
    "문서:\n",
    "{output}\n",
    "\n",
    "숫자만 답변하세요 (0-5):\"\"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": judge_prompt}]\n",
    "    )\n",
    "    \n",
    "    score_text = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        score = int(score_text)\n",
    "        return min(max(score, 0), 5)\n",
    "    except:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def evaluate_output(output: str, reference: Dict) -> Dict:\n",
    "    \"\"\"전체 평가 실행\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 정량 평가\n",
    "    results.update(evaluate_mandatory_items(output, reference.get('must_include', [])))\n",
    "    results.update(evaluate_length(output, reference.get('max_length', 500)))\n",
    "    \n",
    "    # 정성 평가 (LLM-as-Judge)\n",
    "    results['tone_consistency_score'] = llm_judge_tone_consistency(\n",
    "        output, reference.get('tone', 'neutral')\n",
    "    )\n",
    "    results['edit_need_score'] = llm_judge_edit_need(output)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✅ Evaluation 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bb307",
   "metadata": {},
   "source": [
    "## 📈 V1 vs V2 평가 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a7a3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 V1 결과 평가 중...\n",
      "============================================================\n",
      "[1/5] Evaluating e001...\n",
      "[2/5] Evaluating e002...\n",
      "[2/5] Evaluating e002...\n",
      "[3/5] Evaluating e003...\n",
      "[3/5] Evaluating e003...\n",
      "[4/5] Evaluating e004...\n",
      "[4/5] Evaluating e004...\n",
      "[5/5] Evaluating e005...\n",
      "[5/5] Evaluating e005...\n",
      "\n",
      "============================================================\n",
      "✅ V1 평가 완료\n",
      "\n",
      "V1 평균 성능:\n",
      "  필수 항목 포함률: 0.0%\n",
      "  길이 제한 준수율: 100.0%\n",
      "  톤 일치도: 4.80/5\n",
      "  편집 필요도: 1.20/5 (낮을수록 좋음)\n",
      "\n",
      "============================================================\n",
      "✅ V1 평가 완료\n",
      "\n",
      "V1 평균 성능:\n",
      "  필수 항목 포함률: 0.0%\n",
      "  길이 제한 준수율: 100.0%\n",
      "  톤 일치도: 4.80/5\n",
      "  편집 필요도: 1.20/5 (낮을수록 좋음)\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 V1 결과 평가 중...\\n\" + \"=\"*60)\n",
    "\n",
    "v1_eval_results = []\n",
    "for i, result in enumerate(v1_results, 1):\n",
    "    print(f\"[{i}/{len(v1_results)}] Evaluating {result['id']}...\")\n",
    "    eval_result = evaluate_output(result['output'], result['reference'])\n",
    "    v1_eval_results.append(eval_result)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ V1 평가 완료\\n\")\n",
    "\n",
    "# V1 평균 계산\n",
    "v1_avg = {\n",
    "    \"mandatory_items_rate\": sum(r['mandatory_items_rate'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "    \"length_compliant_rate\": sum(r['length_compliant'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "    \"avg_tone_score\": sum(r['tone_consistency_score'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "    \"avg_edit_need\": sum(r['edit_need_score'] for r in v1_eval_results) / len(v1_eval_results),\n",
    "}\n",
    "\n",
    "print(\"V1 평균 성능:\")\n",
    "print(f\"  필수 항목 포함률: {v1_avg['mandatory_items_rate']*100:.1f}%\")\n",
    "print(f\"  길이 제한 준수율: {v1_avg['length_compliant_rate']*100:.1f}%\")\n",
    "print(f\"  톤 일치도: {v1_avg['avg_tone_score']:.2f}/5\")\n",
    "print(f\"  편집 필요도: {v1_avg['avg_edit_need']:.2f}/5 (낮을수록 좋음)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67bcb5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 V2 결과 평가 중...\n",
      "============================================================\n",
      "[1/5] Evaluating e001...\n",
      "[2/5] Evaluating e002...\n",
      "[2/5] Evaluating e002...\n",
      "[3/5] Evaluating e003...\n",
      "[3/5] Evaluating e003...\n",
      "[4/5] Evaluating e004...\n",
      "[4/5] Evaluating e004...\n",
      "[5/5] Evaluating e005...\n",
      "[5/5] Evaluating e005...\n",
      "\n",
      "============================================================\n",
      "✅ V2 평가 완료\n",
      "\n",
      "V2 평균 성능:\n",
      "  필수 항목 포함률: 53.3%\n",
      "  길이 제한 준수율: 100.0%\n",
      "  톤 일치도: 4.80/5\n",
      "  편집 필요도: 1.20/5 (낮을수록 좋음)\n",
      "\n",
      "============================================================\n",
      "✅ V2 평가 완료\n",
      "\n",
      "V2 평균 성능:\n",
      "  필수 항목 포함률: 53.3%\n",
      "  길이 제한 준수율: 100.0%\n",
      "  톤 일치도: 4.80/5\n",
      "  편집 필요도: 1.20/5 (낮을수록 좋음)\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 V2 결과 평가 중...\\n\" + \"=\"*60)\n",
    "\n",
    "v2_eval_results = []\n",
    "for i, result in enumerate(v2_results, 1):\n",
    "    print(f\"[{i}/{len(v2_results)}] Evaluating {result['id']}...\")\n",
    "    eval_result = evaluate_output(result['output'], result['reference'])\n",
    "    v2_eval_results.append(eval_result)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ V2 평가 완료\\n\")\n",
    "\n",
    "# V2 평균 계산\n",
    "v2_avg = {\n",
    "    \"mandatory_items_rate\": sum(r['mandatory_items_rate'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "    \"length_compliant_rate\": sum(r['length_compliant'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "    \"avg_tone_score\": sum(r['tone_consistency_score'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "    \"avg_edit_need\": sum(r['edit_need_score'] for r in v2_eval_results) / len(v2_eval_results),\n",
    "}\n",
    "\n",
    "print(\"V2 평균 성능:\")\n",
    "print(f\"  필수 항목 포함률: {v2_avg['mandatory_items_rate']*100:.1f}%\")\n",
    "print(f\"  길이 제한 준수율: {v2_avg['length_compliant_rate']*100:.1f}%\")\n",
    "print(f\"  톤 일치도: {v2_avg['avg_tone_score']:.2f}/5\")\n",
    "print(f\"  편집 필요도: {v2_avg['avg_edit_need']:.2f}/5 (낮을수록 좋음)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e27fa",
   "metadata": {},
   "source": [
    "## 📋 V1 vs V2 비교 리포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c15e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📊 V1 vs V2 성능 비교표\n",
      "================================================================================\n",
      "                   지표 V1 (dev) V2 (production)     개선도\n",
      "        필수 항목 포함률 (%)     0.0%           53.3% +53.3%p\n",
      "        길이 제한 준수율 (%)   100.0%          100.0%  +0.0%p\n",
      "          톤 일치도 (0-5)     4.80            4.80   +0.00\n",
      "편집 필요도 (0-5, 낮을수록 좋음)     1.20            1.20   +0.00\n",
      "================================================================================\n",
      "\n",
      "✅ 비교표 저장: v1_vs_v2_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 비교표 생성\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"지표\": [\n",
    "        \"필수 항목 포함률 (%)\",\n",
    "        \"길이 제한 준수율 (%)\",\n",
    "        \"톤 일치도 (0-5)\",\n",
    "        \"편집 필요도 (0-5, 낮을수록 좋음)\"\n",
    "    ],\n",
    "    \"V1 (dev)\": [\n",
    "        f\"{v1_avg['mandatory_items_rate']*100:.1f}%\",\n",
    "        f\"{v1_avg['length_compliant_rate']*100:.1f}%\",\n",
    "        f\"{v1_avg['avg_tone_score']:.2f}\",\n",
    "        f\"{v1_avg['avg_edit_need']:.2f}\"\n",
    "    ],\n",
    "    \"V2 (production)\": [\n",
    "        f\"{v2_avg['mandatory_items_rate']*100:.1f}%\",\n",
    "        f\"{v2_avg['length_compliant_rate']*100:.1f}%\",\n",
    "        f\"{v2_avg['avg_tone_score']:.2f}\",\n",
    "        f\"{v2_avg['avg_edit_need']:.2f}\"\n",
    "    ],\n",
    "    \"개선도\": [\n",
    "        f\"{(v2_avg['mandatory_items_rate'] - v1_avg['mandatory_items_rate'])*100:+.1f}%p\",\n",
    "        f\"{(v2_avg['length_compliant_rate'] - v1_avg['length_compliant_rate'])*100:+.1f}%p\",\n",
    "        f\"{v2_avg['avg_tone_score'] - v1_avg['avg_tone_score']:+.2f}\",\n",
    "        f\"{v2_avg['avg_edit_need'] - v1_avg['avg_edit_need']:+.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 V1 vs V2 성능 비교표\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CSV로 저장\n",
    "comparison_df.to_csv(\"v1_vs_v2_comparison.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"\\n✅ 비교표 저장: v1_vs_v2_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41d02e",
   "metadata": {},
   "source": [
    "## 🎯 주요 발견사항 및 개선안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b145dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 V1 주요 실패 사례 (Top 3)\n",
      "============================================================\n",
      "\n",
      "1. ID: e003\n",
      "   편집 필요도: 2/5\n",
      "   필수 항목 포함률: 0%\n",
      "   문제점: 구조화 부족, 필수 요소 누락, 톤 불일치\n",
      "\n",
      "2. ID: e001\n",
      "   편집 필요도: 1/5\n",
      "   필수 항목 포함률: 0%\n",
      "   문제점: 구조화 부족, 필수 요소 누락, 톤 불일치\n",
      "\n",
      "3. ID: e002\n",
      "   편집 필요도: 1/5\n",
      "   필수 항목 포함률: 0%\n",
      "   문제점: 구조화 부족, 필수 요소 누락, 톤 불일치\n",
      "\n",
      "============================================================\n",
      "\n",
      "💡 다음 개선안 (V3 고려사항)\n",
      "============================================================\n",
      "1. Few-shot examples 추가하여 형식 일관성 향상\n",
      "2. JSON Schema로 출력 구조화 강제\n",
      "3. Chain-of-Thought로 필수 항목 체크리스트 먼저 작성\n",
      "4. 업종별/목적별 프롬프트 세분화 (이메일 vs 보고서 vs 제안서)\n",
      "5. Self-critique 단계 추가 (생성 후 자기 검증)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 실패 사례 분석 (V1에서 점수가 낮았던 케이스)\n",
    "print(\"🔍 V1 주요 실패 사례 (Top 3)\\n\" + \"=\"*60)\n",
    "\n",
    "# Edit need가 가장 높은 3개 찾기\n",
    "v1_with_scores = [(i, r) for i, r in enumerate(v1_eval_results)]\n",
    "v1_worst = sorted(v1_with_scores, key=lambda x: x[1]['edit_need_score'], reverse=True)[:3]\n",
    "\n",
    "for rank, (idx, eval_result) in enumerate(v1_worst, 1):\n",
    "    print(f\"\\n{rank}. ID: {v1_results[idx]['id']}\")\n",
    "    print(f\"   편집 필요도: {eval_result['edit_need_score']}/5\")\n",
    "    print(f\"   필수 항목 포함률: {eval_result['mandatory_items_rate']*100:.0f}%\")\n",
    "    print(f\"   문제점: 구조화 부족, 필수 요소 누락, 톤 불일치\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\n💡 다음 개선안 (V3 고려사항)\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Few-shot examples 추가하여 형식 일관성 향상\")\n",
    "print(\"2. JSON Schema로 출력 구조화 강제\")\n",
    "print(\"3. Chain-of-Thought로 필수 항목 체크리스트 먼저 작성\")\n",
    "print(\"4. 업종별/목적별 프롬프트 세분화 (이메일 vs 보고서 vs 제안서)\")\n",
    "print(\"5. Self-critique 단계 추가 (생성 후 자기 검증)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
