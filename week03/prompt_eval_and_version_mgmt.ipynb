{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5b333b",
   "metadata": {},
   "source": [
    "\n",
    "# Week03 — Prompt Evaluation & Version Management (Langfuse + Notion + GitHub)\n",
    "\n",
    "이 노트북은 **회사 회의 STT(회의록 텍스트) 1개**를 입력으로 받아,  \n",
    "- **V0.0.1 (간단 요약 Prompt)**, **V0.0.2 (회사형 구조화 회의록 Prompt)** 두 번의 Prompt Engineering을 수행하고,  \n",
    "- **Langfuse Tracing**을 남기며,  \n",
    "- **Langfuse Datasets**에 평가용 샘플 2개를 업로드하고,  \n",
    "- 이후 **Dataset Run/Evaluation**을 할 수 있도록 기본 코드를 제공합니다.\n",
    "\n",
    "> ⚙️ 이 노트북은 `.env`에 저장된 다음 변수들을 사용합니다.\n",
    "> - `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST` (예: `https://cloud.langfuse.com` 또는 리전 URL)\n",
    "> - `OPENAI_API_KEY` (또는 호환 LLM API 키)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2140f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langfuse\n",
      "  Using cached langfuse-3.6.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (1.34.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (1.34.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (2.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from langfuse) (1.17.2)\n",
      "Requirement already satisfied: anyio in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpx<1.0,>=0.15.4->langfuse) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse)\n",
      "  Using cached opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse)\n",
      "  Using cached opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (5.29.5)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse)\n",
      "  Using cached opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse)\n",
      "  Using cached opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2->langfuse) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2->langfuse) (2.2.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/dhc99/anaconda3/envs/py311/lib/python3.11/site-packages (from anyio->httpx<1.0,>=0.15.4->langfuse) (1.3.1)\n",
      "Using cached langfuse-3.6.1-py3-none-any.whl (350 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Using cached opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Using cached opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Installing collected packages: opentelemetry-proto, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langfuse\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "    Found existing installation: opentelemetry-proto 1.34.0\n",
      "    Uninstalling opentelemetry-proto-1.34.0:\n",
      "      Successfully uninstalled opentelemetry-proto-1.34.0\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.34.0\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.34.0:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.34.0\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.34.0\n",
      "    Uninstalling opentelemetry-api-1.34.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.34.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.55b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.55b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.55b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.34.0\n",
      "    Uninstalling opentelemetry-sdk-1.34.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.34.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-instrumentation-fastapi 0.55b0 requires opentelemetry-semantic-conventions==0.55b0, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation-asgi 0.55b0 requires opentelemetry-semantic-conventions==0.55b0, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-instrumentation 0.55b0 requires opentelemetry-semantic-conventions==0.55b0, but you have opentelemetry-semantic-conventions 0.58b0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.34.0 requires opentelemetry-exporter-otlp-proto-common==1.34.0, but you have opentelemetry-exporter-otlp-proto-common 1.37.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.34.0 requires opentelemetry-proto==1.34.0, but you have opentelemetry-proto 1.37.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.34.0 requires opentelemetry-sdk~=1.34.0, but you have opentelemetry-sdk 1.37.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langfuse-3.6.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0\n"
     ]
    }
   ],
   "source": [
    "!pip install langfuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be11d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env\n",
      "Langfuse host: https://cloud.langfuse.com\n",
      "Langfuse public key set?  True\n",
      "Langfuse secret key set?  True\n",
      "OpenAI key set?  True\n"
     ]
    }
   ],
   "source": [
    "# --- 0) 설치 & 기본 설정 ---------------------------------------------------------\n",
    "# 인터넷 환경에 따라 설치가 제한될 수 있습니다. 로컬 환경에서 실행하세요.\n",
    "# %pip install -q langfuse python-dotenv openai requests\n",
    "\n",
    "import os, json, time, uuid, sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "# .env 로드\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Loaded .env\")\n",
    "except Exception as e:\n",
    "    print(\"python-dotenv not available; make sure environment variables are set.\")\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Langfuse host:\", LANGFUSE_HOST)\n",
    "print(\"Langfuse public key set? \", bool(LANGFUSE_PUBLIC_KEY))\n",
    "print(\"Langfuse secret key set? \", bool(LANGFUSE_SECRET_KEY))\n",
    "print(\"OpenAI key set? \", bool(OPENAI_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8ac2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transcript: LLMOPS 기반 서비스 제작 논의.txt\n",
      "Length: 32345\n",
      "\n",
      "--- Preview (first 800 chars) ---\n",
      "\n",
      "﻿LLMOPS 기반 서비스 제작 논의\n",
      "2025.03.24 월 오후 2:06 ・ 71분 15초\n",
      "차성재\n",
      "\n",
      "\n",
      "참석자 1 00:11\n",
      "그리고 스테이만 오케니안 그다음에 리즘 디테일 트랜지션 컨플루션 그래머 있고 문장 센텐스 컴플렉스티 플렉스티 있고 그리고 스타일 이렇게 맞죠?\n",
      "스타일 맞나 원트 프리 프로 x 플리 마 텐 각각에 대해서 BDP가 있잖아요.\n",
      "그리고 이게 이게 이제 총 4가지로 해가지고 그 베이스 인터미리엣 지금 어드벤스 엑스프리가 엑스프레티 이렇게 있는 거고 총 요 로보인 게 똑같은 게 지금 내 네 세트가 있어요.\n",
      "그래서 이 부장님이 해 주시는 이제 여기서 이게 두 번째로 데이터 생성인데 이 부분이 오토메이션이 옵티메이션까지 안 간다 하더라도 지금 생각해 주시는 게 여기서 이거 갖고서 그러면 이 로그립에 맞는 우리가 데이터를 만들어주자라고 했을 때 그러니까 지금 총 10개의 평가 기준이 평가 항목이 있고 3개의 스케일이 있으니까 이것만 놓고 보면 지금 그렇게 안 하고 있어.\n",
      "\n",
      "참석자 1 01:41\n",
      "그러니까 이제 이 부분이 아마 정의가 좀 안 된 느낌이어 가지고 지금은 이 부장님이 해 주시는 거는 레벨 별로 그러니까 베이식이라는 거에 대해서 한 그때 아마 30개 정도 수주해 주셨나요?\n",
      "제가 20개 20개 근데 이 20개에 대한 매트릭을 이 부장님은 리카운트랑 무슨 램프랑 그리고\n",
      "\n",
      "참석자 2 02:05\n",
      "문단 수 수 아무튼 센텐스 카운트 어려운 단어 개수 AR 레벨 결국 AR 레벨 그게 이제 결과 값에 대한 리베이베이션이고 생성할 때는 베이직이랑 인터네이데이트 그거에 대한 상무님이 적어주신 파라미터 그거 반영해\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1) 회의 STT 텍스트 로드 ------------------------------------------------------\n",
    "transcript_path = \"LLMOPS 기반 서비스 제작 논의.txt\"\n",
    "# 노트북 실행 환경에 해당 파일이 없을 수 있으니 방어적으로 처리\n",
    "transcript_text = \"\"\n",
    "try:\n",
    "    with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        transcript_text = f.read()\n",
    "        print(\"Loaded transcript:\", transcript_path)\n",
    "        print(\"Length:\", len(transcript_text))\n",
    "        print(\"\\n--- Preview (first 800 chars) ---\\n\")\n",
    "        print(transcript_text[:800])\n",
    "except FileNotFoundError:\n",
    "    print(\"Transcript file not found at:\", transcript_path)\n",
    "    transcript_text = \"회의 안건: LLM 기반 평가 파이프라인 정리, 루브릭 및 데이터셋 설계 논의. 참석자: A,B,C... (샘플 텍스트)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108cbc7c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Prompts — V0.0.1 (간단 요약) vs V0.0.2 (구조화 회의록)\n",
    "\n",
    "- **V0.0.1**: 목적 중심의 간단 회의 요약 (한 문단 + bullet 5개 이하)  \n",
    "- **V0.0.2**: 회사용 구조화 회의록 (Decisions / Action Items / Key Points / Risks / Open Questions / Next Steps)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V001_SIMPLE_SUMMARY = '''You are a note-taker for a company meeting.\n",
    "Summarize the meeting transcript concisely for busy stakeholders.\n",
    "Output:\n",
    "- 1-paragraph abstract (<= 120 words)\n",
    "- Top-5 bullets of key points\n",
    "Be neutral and avoid speculation. Do not invent facts. Use present tense.\n",
    "'''\n",
    "\n",
    "V002_STRUCTURED_MINUTES = '''You are an expert corporate minute-taker.\n",
    "Extract structured minutes from the transcript with **no fabrication**.\n",
    "Return Markdown with the following sections (use headings exactly):\n",
    "# Decisions\n",
    "- [Decision] <concise statement> (owner if applicable)\n",
    "\n",
    "# Action Items\n",
    "- [Task] <what> — Owner: <name or \"TBD\"> — Due: <YYYY-MM-DD or \"TBD\">\n",
    "\n",
    "# Key Discussion Points\n",
    "- <point 1>\n",
    "- <point 2>\n",
    "\n",
    "# Risks\n",
    "- <risk 1 (cause → impact → mitigation)>\n",
    "\n",
    "# Open Questions\n",
    "- <question 1>\n",
    "\n",
    "# Next Steps\n",
    "- <step 1 (who/when)>\n",
    "\n",
    "Rules:\n",
    "- Quote numbers/dates only if present in the transcript; otherwise write \"TBD\".\n",
    "- Do not include PII beyond names mentioned.\n",
    "- Keep each bullet <= 25 words.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73550eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3) LLM 호출 추상화 -----------------------------------------------------------\n",
    "def call_openai_chat(system_prompt: str, user_text: str, model: str = \"gpt-4o-mini\", temperature: float = 0.2) -> str:\n",
    "    \"\"\"LLM 호출. OPENAI_API_KEY가 없으면 모의 출력(mock)으로 대체.\"\"\"\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        try:\n",
    "            # Try official openai package first\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text},\n",
    "                    ],\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "                return resp.choices[0].message.content\n",
    "            except Exception:\n",
    "                # Fallback to raw HTTP if new package not available\n",
    "                import requests\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\",\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text},\n",
    "                    ],\n",
    "                    \"temperature\": temperature,\n",
    "                }\n",
    "                r = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload, timeout=60)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            print(\"OpenAI call failed, falling back to mock. Error:\", e)\n",
    "    # Mock output for offline demo\n",
    "    return f\"\"\"[MOCK OUTPUT]\\nSystem: {system_prompt.splitlines()[0]}\\nUserInputPreview: {user_text[:120]}...\\n- Bullet 1\\n- Bullet 2\\n- Bullet 3\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0eb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse SDK authenticated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4) Langfuse 초기화 & Tracing 유틸 -------------------------------------------\n",
    "USE_SDK = False\n",
    "langfuse = None\n",
    "\n",
    "try:\n",
    "    from langfuse import get_client, observe\n",
    "    from langfuse.openai import OpenAI as LFOpenAI  # optional\n",
    "    langfuse = get_client()\n",
    "    if langfuse and langfuse.auth_check():\n",
    "        USE_SDK = True\n",
    "        print(\"Langfuse SDK authenticated.\")\n",
    "    else:\n",
    "        print(\"Langfuse SDK not authenticated; will use HTTP or no-op.\")\n",
    "except Exception as e:\n",
    "    print(\"Langfuse SDK not available; continuing without it.\", e)\n",
    "\n",
    "def start_trace(name: str, metadata: Dict[str, Any] = None):\n",
    "    if USE_SDK:\n",
    "        # Start span as root trace context manager\n",
    "        return langfuse.start_as_current_span(name=name, metadata=metadata or {})\n",
    "    else:\n",
    "        # No-op context manager\n",
    "        from contextlib import contextmanager\n",
    "        @contextmanager\n",
    "        def _noop():\n",
    "            class Dummy:\n",
    "                def score_trace(self, *args, **kwargs): pass\n",
    "                def update_trace(self, *args, **kwargs): pass\n",
    "            yield Dummy()\n",
    "        return _noop()\n",
    "\n",
    "def log_trace_io(input_obj: Any, output_obj: Any):\n",
    "    if USE_SDK:\n",
    "        try:\n",
    "            # update current trace input/output to enable dataset evals linkage\n",
    "            langfuse.update_current_trace(input=input_obj, output=output_obj)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to update current trace:\", e)\n",
    "\n",
    "def flush_langfuse():\n",
    "    try:\n",
    "        if USE_SDK:\n",
    "            langfuse.flush()\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc6902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== V0.0.1 (simple) ===\n",
      " **Abstract:**  \n",
      "The meeting discusses the development of a service based on LLMOPS, focusing on the creation of evaluation metrics and data generation processes. Participants emphasize the need for clear definitions and parameters for evaluating generated content, including aspects such as sentence complexity and vocabulary difficulty. They explore the automation of data generation and the importance of diverse outputs for effective evaluation. The conversation highlights the necessity of refining the rubric and establishing a systematic approach to ensure that generated data meets the desired quality and variation.\n",
      "\n",
      "**Key Points:**\n",
      "- Discussion on LLMOPS-based service creation and evaluation metrics.\n",
      "- Emphasis on defining parameters for content evaluation, including sentence complexity a ...\n",
      "\n",
      "=== V0.0.2 (structured) ===\n",
      " # Decisions\n",
      "- Define evaluation metrics for data generation (owner: TBD)\n",
      "\n",
      "# Action Items\n",
      "- Create a detailed rubric for evaluation metrics — Owner: TBD — Due: TBD\n",
      "- Develop a pipeline for automated data generation — Owner: TBD — Due: TBD\n",
      "\n",
      "# Key Discussion Points\n",
      "- Current evaluation metrics are insufficient for diverse data generation.\n",
      "- Need for a structured approach to input and output in data automation.\n",
      "\n",
      "# Risks\n",
      "- Insufficient variation in generated data could lead to ineffective evaluations (cause → limited metrics → enhance metrics and automation).\n",
      "\n",
      "# Open Questions\n",
      "- How can we ensure the generated data meets the required diversity for effective evaluation?\n",
      "\n",
      "# Next Steps\n",
      "- Discuss automation strategies and metrics evaluation by TBD (when: TBD). ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5) 두 가지 Prompt 실행 + Tracing --------------------------------------------\n",
    "subset = transcript_text[:4000]  # 데모를 위해 앞부분만 사용\n",
    "\n",
    "results = {}\n",
    "\n",
    "with start_trace(name=\"meeting-minutes:v0.0.1\", metadata={\"version\": \"v0.0.1\", \"label\": \"dev\", \"use_case\":\"meeting-minutes\"}) as span:\n",
    "    out1 = call_openai_chat(V001_SIMPLE_SUMMARY, subset)\n",
    "    results[\"v0.0.1\"] = out1\n",
    "    log_trace_io({\"transcript\": subset, \"prompt_version\": \"v0.0.1\"}, {\"minutes\": out1})\n",
    "\n",
    "with start_trace(name=\"meeting-minutes:v0.0.2\", metadata={\"version\": \"v0.0.2\", \"label\": \"staging\", \"use_case\":\"meeting-minutes\"}) as span:\n",
    "    out2 = call_openai_chat(V002_STRUCTURED_MINUTES, subset)\n",
    "    results[\"v0.0.2\"] = out2\n",
    "    log_trace_io({\"transcript\": subset, \"prompt_version\": \"v0.0.2\"}, {\"minutes\": out2})\n",
    "\n",
    "flush_langfuse()\n",
    "\n",
    "print(\"\\n=== V0.0.1 (simple) ===\\n\", results[\"v0.0.1\"][:800], \"...\")\n",
    "print(\"\\n=== V0.0.2 (structured) ===\\n\", results[\"v0.0.2\"][:800], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffda36",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Langfuse Dataset 생성 & 아이템 업로드 (샘플 2개)\n",
    "\n",
    "- 회의록 일부를 input으로, 기대 구조를 reference로 저장합니다.  \n",
    "- 이후 Langfuse에서 **Dataset Run**을 실행하여, 각 Prompt 버전의 결과를 비교/평가할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fcdd8",
   "metadata": {},
   "source": [
    "### JSONL 파일에 저장된 내용\n",
    "\n",
    "선택된 코드(7번 셀)에서 로컬 `datasets/week03_meeting_minutes_demo.jsonl` 파일에 **데이터셋 샘플 2개를 JSON Lines 형식으로 저장**합니다. JSONL은 각 줄이 하나의 JSON 객체인 텍스트 파일입니다.\n",
    "\n",
    "#### 저장된 데이터 구조\n",
    "파일 내용 예시 (실제 파일을 읽어보면):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf5b10",
   "metadata": {
    "vscode": {
     "languageId": "jsonl"
    }
   },
   "outputs": [],
   "source": [
    "{\"input\": {\"transcript\": \"회의 텍스트 일부...\"}, \"expected_output\": {\"sections\": [\"Decisions\", \"Action Items\", \"Key Discussion Points\", \"Next Steps\"]}}\n",
    "{\"input\": {\"transcript\": \"회의 텍스트 다른 일부...\"}, \"expected_output\": {\"sections\": [\"Decisions\", \"Action Items\", \"Risks\", \"Open Questions\", \"Next Steps\"]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c552a3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **각 줄**: `item1`과 `item2` 딕셔너리를 `json.dumps()`로 JSON 문자열로 변환.\n",
    "- **item1**: 회의 텍스트 앞부분 + 기대 섹션 4개.\n",
    "- **item2**: 회의 텍스트 중간부분 + 기대 섹션 5개.\n",
    "- **목적**: Langfuse SDK 없이 수동으로 데이터셋 업로드할 때 백업용.\n",
    "\n",
    "#### 확인 방법\n",
    "터미널에서 `cat datasets/week03_meeting_minutes_demo.jsonl` 실행하면 내용 확인 가능. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144d0eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset 'week03_meeting_minutes_demo' with 2 items via SDK.\n",
      "Local backup dataset written to /home/dhc99/ajou-llmops-2025-2nd-semester/week03/datasets/week03_meeting_minutes_demo.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset 이름\n",
    "DATASET_NAME = \"week03_meeting_minutes_demo\"\n",
    "\n",
    "# 샘플 아이템 2개 (간단 예시)\n",
    "item1 = {\n",
    "    \"input\": {\"transcript\": subset[:1500]},\n",
    "    \"expected_output\": {\n",
    "        \"sections\": [\"Decisions\",\"Action Items\",\"Key Discussion Points\",\"Next Steps\"],  # 기대 섹션 존재성\n",
    "    }\n",
    "}\n",
    "item2 = {\n",
    "    \"input\": {\"transcript\": subset[1500:3000] if len(subset) > 3000 else subset},\n",
    "    \"expected_output\": {\n",
    "        \"sections\": [\"Decisions\",\"Action Items\",\"Risks\",\"Open Questions\",\"Next Steps\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "created = False\n",
    "if USE_SDK:\n",
    "    try:\n",
    "        langfuse.create_dataset(name=DATASET_NAME)\n",
    "        for item in (item1, item2):\n",
    "            langfuse.create_dataset_item(\n",
    "                dataset_name=DATASET_NAME,\n",
    "                input=item[\"input\"],\n",
    "                expected_output=item[\"expected_output\"]\n",
    "            )\n",
    "        created = True\n",
    "        print(f\"Created dataset '{DATASET_NAME}' with 2 items via SDK.\")\n",
    "    except Exception as e:\n",
    "        print(\"SDK dataset creation failed:\", e)\n",
    "\n",
    "# 로컬 JSONL도 함께 저장(백업/수동 업로드용)\n",
    "ds_dir = Path(\"datasets\"); ds_dir.mkdir(exist_ok=True)\n",
    "jsonl_path = ds_dir / f\"{DATASET_NAME}.jsonl\"\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in (item1, item2):\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Local backup dataset written to\", jsonl_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56eb65",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (선택) Native Dataset Run 실행 예시\n",
    "\n",
    "아래 코드는 Langfuse **Datasets Cookbook**의 패턴을 따라, 각 Dataset Item을 순회하며 애플리케이션을 실행하고  \n",
    "`root_span.score_trace(...)` 등으로 평가 스코어를 기록합니다.  \n",
    "실행 전, SDK 인증이 되어 있어야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc406f",
   "metadata": {},
   "source": [
    "### 선택된 코드 설명 (8번 셀: Native Dataset Run 실행 예시)\n",
    "\n",
    "이 코드는 **Langfuse 데이터셋을 기반으로 프롬프트 버전을 자동 평가**하는 역할을 합니다. 데이터셋의 각 샘플에 대해 LLM을 실행하고, 결과를 트레이싱하며 성능 지표를 계산합니다.\n",
    "\n",
    "#### 주요 함수\n",
    "1. **`presence_of_sections_eval(output_text, expected_sections)`**:\n",
    "   - **목적**: LLM 출력에 기대 섹션(예: \"# Decisions\", \"# Action Items\")이 얼마나 포함되는지 확인.\n",
    "   - **로직**: 텍스트에서 섹션 헤더를 검색해 일치 개수를 세고, 총 기대 섹션 수로 나누어 0.0~1.0 스코어 반환.\n",
    "   - **예시**: 기대 섹션 4개 중 3개 포함 → 0.75.\n",
    "\n",
    "2. **`run_dataset_experiment(run_name, system_prompt)`**:\n",
    "   - **목적**: 데이터셋 아이템을 순회하며 프롬프트 실행 → 트레이싱 → 평가.\n",
    "   - **로직**:\n",
    "     - 데이터셋 로드 (`langfuse.get_dataset(DATASET_NAME)`).\n",
    "     - 각 아이템에 대해: LLM 호출 → 입력/출력 트레이스 기록 → 섹션 커버리지 스코어 계산 → Langfuse에 기록.\n",
    "     - `root_span.score_trace(\"section_coverage\", score)`로 평가 지표 저장.\n",
    "   - **출력**: \"Finished dataset run 'minutes_v0.0.2' on dataset 'week03_meeting_minutes_demo'.\"\n",
    "\n",
    "#### 왜 필요하나?\n",
    "- **자동 평가**: 수동 비교 대신 데이터셋 기반으로 프롬프트 성능 측정 (예: 구조화 프롬프트가 섹션을 더 잘 생성하는지).\n",
    "- **Langfuse 연동**: 트레이스와 스코어를 콘솔에서 확인 가능.\n",
    "- **실행**: 주석 해제 후 `run_dataset_experiment(run_name=\"minutes_v0.0.2\", system_prompt=V002_STRUCTURED_MINUTES)` 호출.\n",
    "\n",
    "이 셀은 프롬프트 버전 비교의 핵심으로, 실행 후 Langfuse에서 \"section_coverage\" 지표를 분석할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bee8fb",
   "metadata": {},
   "source": [
    "### 기대 섹션(Expected Sections)이란?\n",
    "\n",
    "**기대 섹션**은 **LLM이 출력해야 하는 이상적인 구조(섹션 헤더)를 미리 정의한 리스트**입니다. 평가 시 LLM 출력에 이 섹션들이 얼마나 포함되는지 확인합니다.\n",
    "\n",
    "#### 코드 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6641f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1 = {\n",
    "    \"input\": {\"transcript\": subset[:1500]},\n",
    "    \"expected_output\": {\n",
    "        \"sections\": [\"Decisions\", \"Action Items\", \"Key Discussion Points\", \"Next Steps\"],  # ← 기대 섹션\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c79800",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **출처**: 데이터셋 생성 시 수동 정의 (V002_STRUCTURED_MINUTES 프롬프트 기반).\n",
    "- **목적**: 프롬프트의 구조화 성능 평가 기준.\n",
    "\n",
    "#### 예시\n",
    "- **프롬프트 V0.0.2**: \"# Decisions\", \"# Action Items\" 등 섹션 생성 지시.\n",
    "- **기대 섹션**: `[\"Decisions\", \"Action Items\", \"Risks\", \"Open Questions\", \"Next Steps\"]`\n",
    "- **평가**: 출력에 이 섹션들이 포함되면 Score 상승.\n",
    "\n",
    "기대 섹션은 \"이 프롬프트로 이 구조를 만들어야 함\"을 명시한 기준입니다. 더 궁금한 점 있으신가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02db63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished dataset run 'minutes_v0.0.2' on dataset 'week03_meeting_minutes_demo'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def presence_of_sections_eval(output_text: str, expected_sections) -> float:\n",
    "    \"\"\"출력에 예상 섹션 헤더가 얼마나 포함되는지 0.0~1.0 반환.\"\"\"\n",
    "    if not output_text:\n",
    "        return 0.0\n",
    "    hits = 0\n",
    "    for sec in expected_sections:\n",
    "        if f\"# {sec}\" in output_text or sec in output_text:\n",
    "            hits += 1\n",
    "    return hits / max(1, len(expected_sections))\n",
    "\n",
    "def run_dataset_experiment(run_name: str, system_prompt: str):\n",
    "    if not USE_SDK:\n",
    "        print(\"Langfuse SDK unavailable; skipping remote run.\")\n",
    "        return\n",
    "    dataset = langfuse.get_dataset(DATASET_NAME)\n",
    "    for item in dataset.items:\n",
    "        with item.run(run_name=run_name) as root_span:\n",
    "            output = call_openai_chat(system_prompt, item.input[\"transcript\"])\n",
    "            # Trace IO를 업데이트해야 Langfuse의 Eval 기능에서 인풋/아웃풋을 인식합니다.\n",
    "            root_span.update_trace(input=item.input, output=output)\n",
    "            # 간단한 구조성 스코어 예시\n",
    "            score = presence_of_sections_eval(output, item.expected_output.get(\"sections\", []))\n",
    "            root_span.score_trace(name=\"section_coverage\", value=score)\n",
    "    langfuse.flush()\n",
    "    print(f\"Finished dataset run '{run_name}' on dataset '{DATASET_NAME}'.\")\n",
    "\n",
    "# 예시 실행 (주석 해제하여 사용)\n",
    "run_dataset_experiment(run_name=\"minutes_v0.0.2\", system_prompt=V002_STRUCTURED_MINUTES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdd895",
   "metadata": {},
   "source": [
    "\n",
    "## 8) (선택) Langfuse Prompt 버전 생성 & 라벨 지정 (REST API 예시)\n",
    "\n",
    "- 동일 `promptName`으로 새 버전을 생성하면 자동으로 버전이 증분됩니다.  \n",
    "- `labels`에 `staging`, `production` 등을 부여/변경하여 배포 포인터로 사용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b95806",
   "metadata": {},
   "source": [
    "### 이 JSON 객체 설명\n",
    "\n",
    "이건 **Langfuse API에서 프롬프트 버전을 생성한 후 반환된 응답 데이터**입니다. `create_prompt_version_via_rest` 함수 실행 결과예요.\n",
    "\n",
    "#### 주요 필드 설명\n",
    "- **`id`**: 프롬프트 버전의 고유 ID (예: `29d29769-8408-48ca-907a-3238fef4b52e`).\n",
    "- **`createdAt` / `updatedAt`**: 생성/수정 시간 (ISO 8601 형식, UTC).\n",
    "- **`projectId`**: Langfuse 프로젝트 ID.\n",
    "- **`createdBy`**: 생성자 (\"API\"로 API 호출).\n",
    "- **`prompt`**: 업로드된 프롬프트 텍스트 (V002_STRUCTURED_MINUTES 내용).\n",
    "- **`name`**: 프롬프트 이름 (\"meeting-minutes\").\n",
    "- **`version`**: 버전 번호 (2, 자동 증분).\n",
    "- **`type`**: 프롬프트 타입 (\"text\").\n",
    "- **`config`**: 모델 설정 (model_name: \"gpt-4o-mini\", temperature: 0.2).\n",
    "- **`labels`**: 태그 리스트 ([\"production\", \"latest\"] – 배포 환경 지정).\n",
    "- **`tags`**: 추가 태그 (빈 리스트).\n",
    "\n",
    "#### 왜 반환되나?\n",
    "- **성공 확인**: 함수가 정상 실행되면 이 JSON을 반환 (실패 시 에러).\n",
    "- **메타데이터**: Langfuse 콘솔에서 이 버전을 조회/관리할 때 사용.\n",
    "\n",
    "이 데이터는 프롬프트 버전이 성공적으로 생성되었음을 의미합니다. Langfuse 콘솔에서 확인 가능해요. 더 궁금한 점 있으신가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72665ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '29d29769-8408-48ca-907a-3238fef4b52e',\n",
       " 'createdAt': '2025-10-06T09:02:29.239Z',\n",
       " 'updatedAt': '2025-10-06T09:02:29.239Z',\n",
       " 'projectId': 'cmgdwile006tdad0774oq3lk9',\n",
       " 'createdBy': 'API',\n",
       " 'prompt': 'You are an expert corporate minute-taker.\\nExtract structured minutes from the transcript with **no fabrication**.\\nReturn Markdown with the following sections (use headings exactly):\\n# Decisions\\n- [Decision] <concise statement> (owner if applicable)\\n\\n# Action Items\\n- [Task] <what> — Owner: <name or \"TBD\"> — Due: <YYYY-MM-DD or \"TBD\">\\n\\n# Key Discussion Points\\n- <point 1>\\n- <point 2>\\n\\n# Risks\\n- <risk 1 (cause → impact → mitigation)>\\n\\n# Open Questions\\n- <question 1>\\n\\n# Next Steps\\n- <step 1 (who/when)>\\n\\nRules:\\n- Quote numbers/dates only if present in the transcript; otherwise write \"TBD\".\\n- Do not include PII beyond names mentioned.\\n- Keep each bullet <= 25 words.\\n',\n",
       " 'name': 'meeting-minutes',\n",
       " 'version': 2,\n",
       " 'type': 'text',\n",
       " 'isActive': None,\n",
       " 'config': {'model_name': 'gpt-4o-mini', 'temperature': 0.2},\n",
       " 'tags': [],\n",
       " 'labels': ['production', 'latest'],\n",
       " 'commitMessage': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import base64, json\n",
    "\n",
    "def lf_auth_headers():\n",
    "    token = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "    return {\"Authorization\": f\"Basic {token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "def create_prompt_version_via_rest(prompt_name: str, prompt_text: str, model_name: str, labels=None):\n",
    "    if not (LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY):\n",
    "        print(\"Missing Langfuse credentials.\")\n",
    "        return None\n",
    "    import requests\n",
    "    url = f\"{LANGFUSE_HOST.rstrip('/')}/api/public/v2/prompts\"\n",
    "    payload = {\n",
    "        \"name\": prompt_name,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"config\": {\"model_name\": model_name, \"temperature\": 0.2},\n",
    "        \"labels\": labels or []\n",
    "    }\n",
    "    r = requests.post(url, headers=lf_auth_headers(), json=payload, timeout=30)\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(\"Prompt creation failed:\", r.status_code, r.text)\n",
    "        raise\n",
    "    return r.json()\n",
    "\n",
    "# 예시: v0.1 → v0.2 (staging → production) 업로드 (주석 해제 후 사용)\n",
    "create_prompt_version_via_rest(\"meeting-minutes\", V001_SIMPLE_SUMMARY, \"gpt-4o-mini\", labels=[\"staging\"])\n",
    "create_prompt_version_via_rest(\"meeting-minutes\", V002_STRUCTURED_MINUTES, \"gpt-4o-mini\", labels=[\"production\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9552155",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Prompty 파일 생성 (GitHub PR용)\n",
    "\n",
    "- `prompts/meeting_minutes_v0.1.prompty`  \n",
    "- `prompts/meeting_minutes_v0.2.prompty`  \n",
    "를 생성합니다. (PR 시 `v0.1 → v0.2` 변경 경험 포함)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc732570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Prompty files:\n",
      "- meeting_minutes_v0.1.prompty\n",
      "- meeting_minutes_v0.2.prompty\n"
     ]
    }
   ],
   "source": [
    "# --- 9) Prompty 파일 생성 (GitHub PR용) ---------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Prompty 파일들을 위한 디렉토리 생성\n",
    "prompts_dir = Path(\"week03/prompts\")\n",
    "prompts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# V0.1 Prompty 파일 생성\n",
    "v01_prompty = \"\"\"name: Meeting Minutes - Simple Summary\n",
    "version: v0.1.0\n",
    "description: Summarize a meeting transcript into a short abstract and top-5 bullets.\n",
    "inputs:\n",
    "  transcript:\n",
    "    type: string\n",
    "outputs:\n",
    "  response_format: markdown\n",
    "---\n",
    "system:\n",
    "You are a note-taker for a company meeting.\n",
    "Summarize the meeting transcript concisely for busy stakeholders.\n",
    "Output:\n",
    "- 1-paragraph abstract (<= 120 words)\n",
    "- Top-5 bullets of key points\n",
    "Be neutral and avoid speculation. Do not invent facts. Use present tense.\n",
    "user:\n",
    "{{ transcript }}\n",
    "\"\"\"\n",
    "\n",
    "# V0.2 Prompty 파일 생성\n",
    "v02_prompty = \"\"\"name: Meeting Minutes - Structured Corporate\n",
    "version: v0.2.0\n",
    "description: Produce structured company-grade minutes with Decisions, Action Items (owner/due), Risks, etc.\n",
    "inputs:\n",
    "  transcript:\n",
    "    type: string\n",
    "outputs:\n",
    "  response_format: markdown\n",
    "---\n",
    "system:\n",
    "You are an expert corporate minute-taker.\n",
    "Extract structured minutes from the transcript with **no fabrication**.\n",
    "Return Markdown with the following sections (use headings exactly):\n",
    "# Decisions\n",
    "- [Decision] <concise statement> (owner if applicable)\n",
    "\n",
    "# Action Items\n",
    "- [Task] <what> — Owner: <name or \"TBD\"> — Due: <YYYY-MM-DD or \"TBD\">\n",
    "\n",
    "# Key Discussion Points\n",
    "- <point 1>\n",
    "- <point 2>\n",
    "\n",
    "# Risks\n",
    "- <risk 1 (cause → impact → mitigation)>\n",
    "\n",
    "# Open Questions\n",
    "- <question 1>\n",
    "\n",
    "# Next Steps\n",
    "- <step 1 (who/when)>\n",
    "\n",
    "Rules:\n",
    "- Quote numbers/dates only if present in the transcript; otherwise write \"TBD\".\n",
    "- Do not include PII beyond names mentioned.\n",
    "- Keep each bullet <= 25 words.\n",
    "user:\n",
    "{{ transcript }}\n",
    "\"\"\"\n",
    "\n",
    "# 파일 저장\n",
    "with open(prompts_dir / \"meeting_minutes_v0.1.prompty\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(v01_prompty)\n",
    "\n",
    "with open(prompts_dir / \"meeting_minutes_v0.2.prompty\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(v02_prompty)\n",
    "\n",
    "print(\"Created Prompty files:\")\n",
    "print(\"- meeting_minutes_v0.1.prompty\")\n",
    "print(\"- meeting_minutes_v0.2.prompty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "669aaa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompty files:\n",
      "- meeting_minutes_v0.1.prompty\n",
      "- meeting_minutes_v0.2.prompty\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "print(\"Prompty files:\")\n",
    "for p in Path(\"week03/prompts\").glob(\"*.prompty\"):\n",
    "    print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c93ce",
   "metadata": {},
   "source": [
    "\n",
    "## 10) 마무리 & 다음 단계\n",
    "1. **Tracing 확인**: Langfuse 콘솔에서 오늘 생성된 트레이스를 확인합니다.  \n",
    "2. **Dataset Run**: `run_dataset_experiment(...)` 실행 후 지표(예: `section_coverage`) 확인.  \n",
    "3. **Prompt 배포 라벨**: REST 또는 UI로 `staging` → `production` 라벨 전환.  \n",
    "4. **GitHub PR**: `prompts/meeting_minutes_v0.1.prompty` → `v0.2` 변경 포함 PR 생성.  \n",
    "5. **초대**: 프로젝트에 `smilechacha@ajou.ac.kr` 뷰어 이상 권한 초대.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
