{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215b7785",
   "metadata": {},
   "source": [
    "# Assignment 02 - Part 2: Pinecone Indexing & Embeddings\n",
    "\n",
    "## ëª©í‘œ\n",
    "- BGE-M3 ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
    "- Pinecone ì¸ë±ìŠ¤ ìƒì„±\n",
    "- ì²­í¬ ë°ì´í„° ì„ë² ë”© ë° ì—…ë¡œë“œ\n",
    "- BM25 ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebe214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhc99/anaconda3/envs/torch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project initialized\n",
      "   Data: /home/dhc99/ajou-llmops-2025-2nd-semester/assignment02/datasets\n",
      "   Artifacts: /home/dhc99/ajou-llmops-2025-2nd-semester/assignment02/artifacts\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "# Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BM25\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path('/home/dhc99/ajou-llmops-2025-2nd-semester/assignment02')\n",
    "DATA_DIR = PROJECT_ROOT / 'datasets'\n",
    "CONFIG_DIR = PROJECT_ROOT / 'configs'\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / 'artifacts'\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Project initialized\")\n",
    "print(f\"   Data: {DATA_DIR}\")\n",
    "print(f\"   Artifacts: {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa11c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Configuration:\n",
      "  - Embedding Model: BAAI/bge-m3\n",
      "  - Pinecone Index: rag-assignment-korquad\n",
      "  - Vector Dimension: 1024\n",
      "  - Metric: cosine\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì • ë¡œë“œ\n",
    "with open(CONFIG_DIR / 'models.yaml', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"ğŸ“‹ Configuration:\")\n",
    "print(f\"  - Embedding Model: {config['embedding']['model_name']}\")\n",
    "print(f\"  - Pinecone Index: {config['pinecone']['index_name']}\")\n",
    "print(f\"  - Vector Dimension: {config['pinecone']['dimension']}\")\n",
    "print(f\"  - Metric: {config['pinecone']['metric']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef668e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 641 chunks\n",
      "\n",
      "ğŸ“Š Sample chunk:\n",
      "chunk_id                                  6566495-0-0_chunk_0\n",
      "text        1839ë…„ ë°”ê·¸ë„ˆëŠ” ê´´í…Œì˜ íŒŒìš°ìŠ¤íŠ¸ì„ ì²˜ìŒ ì½ê³  ê·¸ ë‚´ìš©ì— ë§ˆìŒì´ ëŒë ¤ ì´ë¥¼ ì†Œì¬ë¡œ...\n",
      "title                                                 íŒŒìš°ìŠ¤íŠ¸_ì„œê³¡\n",
      "doc_id                                            6566495-0-0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ì²­í¬ ë°ì´í„° ë¡œë“œ\n",
    "chunks_df = pd.read_parquet(DATA_DIR / 'corpus_chunks.parquet')\n",
    "print(f\"âœ… Loaded {len(chunks_df):,} chunks\")\n",
    "print(f\"\\nğŸ“Š Sample chunk:\")\n",
    "print(chunks_df.iloc[0][['chunk_id', 'text', 'title', 'doc_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc733a7",
   "metadata": {},
   "source": [
    "## 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c1e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading embedding model...\n",
      "   Trying with safetensors...\n",
      "   âš ï¸  Safetensors failed: BAAI/bge-m3 does not appear to have a file named model.safetensors or model.safetensors.index.json and thus cannot be loaded with `safetensors`. Please make sure that the model has been saved with `safe_serialization=True` or do not set `use_safetensors=True`.\n",
      "   Trying alternative model: intfloat/multilingual-e5-large...\n",
      "   âœ… Loaded multilingual-e5-large!\n",
      "\n",
      "âœ… Model loaded: intfloat/multilingual-e5-large\n",
      "   Max sequence length: 512\n",
      "   Embedding dimension: 1024\n",
      "\n",
      "âœ… Test embedding shape: (1024,)\n",
      "   Dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "# BGE-M3 ëª¨ë¸ ë¡œë“œ (safetensors ì‚¬ìš©)\n",
    "print(\"ğŸ“¥ Loading embedding model...\")\n",
    "\n",
    "# ë°©ë²• 1: safetensors ì‚¬ìš© (ê°€ì¥ ì•ˆì „)\n",
    "try:\n",
    "    print(\"   Trying with safetensors...\")\n",
    "    embedding_model = SentenceTransformer(\n",
    "        config['embedding']['model_name'],\n",
    "        device='cuda' if config['embedding']['device'] == 'cuda' else 'cpu',\n",
    "        model_kwargs={'use_safetensors': True}  # safetensors ê°•ì œ ì‚¬ìš©\n",
    "    )\n",
    "    print(\"   âœ… Loaded with safetensors!\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸  Safetensors failed: {e}\")\n",
    "    \n",
    "    # ë°©ë²• 2: ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš© (multilingual-e5)\n",
    "    try:\n",
    "        print(\"   Trying alternative model: intfloat/multilingual-e5-large...\")\n",
    "        embedding_model = SentenceTransformer(\n",
    "            \"intfloat/multilingual-e5-large\",\n",
    "            device='cuda' if config['embedding']['device'] == 'cuda' else 'cpu'\n",
    "        )\n",
    "        print(\"   âœ… Loaded multilingual-e5-large!\")\n",
    "        # config ì—…ë°ì´íŠ¸\n",
    "        config['embedding']['model_name'] = \"intfloat/multilingual-e5-large\"\n",
    "        config['pinecone']['dimension'] = 1024  # e5-large dimension\n",
    "    except Exception as e2:\n",
    "        print(f\"   âš ï¸  Alternative model failed: {e2}\")\n",
    "        \n",
    "        # ë°©ë²• 3: ë” ì‘ì€ ëª¨ë¸ (all-MiniLM-L6-v2)\n",
    "        print(\"   Trying smaller model: paraphrase-multilingual-MiniLM-L12-v2...\")\n",
    "        embedding_model = SentenceTransformer(\n",
    "            \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "            device='cuda' if config['embedding']['device'] == 'cuda' else 'cpu'\n",
    "        )\n",
    "        print(\"   âœ… Loaded paraphrase-multilingual-MiniLM-L12-v2!\")\n",
    "        # config ì—…ë°ì´íŠ¸\n",
    "        config['embedding']['model_name'] = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "        config['pinecone']['dimension'] = 384  # MiniLM dimension\n",
    "\n",
    "print(f\"\\nâœ… Model loaded: {config['embedding']['model_name']}\")\n",
    "print(f\"   Max sequence length: {embedding_model.max_seq_length}\")\n",
    "print(f\"   Embedding dimension: {config['pinecone']['dimension']}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì„ë² ë”©\n",
    "test_text = \"ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤.\"\n",
    "test_embedding = embedding_model.encode(test_text, normalize_embeddings=config['embedding']['normalize'])\n",
    "print(f\"\\nâœ… Test embedding shape: {test_embedding.shape}\")\n",
    "print(f\"   Dimension: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f0517f",
   "metadata": {},
   "source": [
    "## 2. Pinecone ì´ˆê¸°í™” ë° ì¸ë±ìŠ¤ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3158a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Existing indexes: ['rag-korquad-demo']\n",
      "\n",
      "ğŸ”§ Creating index 'rag-assignment-korquad'...\n",
      "âœ… Index 'rag-assignment-korquad' created\n",
      "âœ… Index is ready!\n",
      "\n",
      "ğŸ“Š Index stats:\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Pinecone ì´ˆê¸°í™”\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ PINECONE_API_KEY not found in environment variables\")\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# ì¸ë±ìŠ¤ ì´ë¦„\n",
    "index_name = config['pinecone']['index_name']\n",
    "\n",
    "# ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "print(f\"ğŸ“‹ Existing indexes: {existing_indexes}\")\n",
    "\n",
    "# ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‚­ì œ (ì„ íƒì )\n",
    "if index_name in existing_indexes:\n",
    "    print(f\"âš ï¸  Index '{index_name}' already exists.\")\n",
    "    response = input(\"Delete and recreate? (yes/no): \")\n",
    "    if response.lower() == 'yes':\n",
    "        pc.delete_index(index_name)\n",
    "        print(f\"ğŸ—‘ï¸  Deleted index '{index_name}'\")\n",
    "        time.sleep(5)  # Wait for deletion\n",
    "\n",
    "# ìƒˆ ì¸ë±ìŠ¤ ìƒì„±\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f\"\\nğŸ”§ Creating index '{index_name}'...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=config['pinecone']['dimension'],\n",
    "        metric=config['pinecone']['metric'],\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=config['pinecone']['cloud'],\n",
    "            region=config['pinecone']['region']\n",
    "        )\n",
    "    )\n",
    "    print(f\"âœ… Index '{index_name}' created\")\n",
    "    \n",
    "    # Wait for index to be ready\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        print(\"   Waiting for index to be ready...\")\n",
    "        time.sleep(5)\n",
    "    print(\"âœ… Index is ready!\")\n",
    "\n",
    "# ì¸ë±ìŠ¤ ì—°ê²°\n",
    "index = pc.Index(index_name)\n",
    "print(f\"\\nğŸ“Š Index stats:\")\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a7053a",
   "metadata": {},
   "source": [
    "## 3. ì„ë² ë”© ìƒì„± ë° Pinecone ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1604fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Creating embeddings for 641 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings created: (641, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_embeddings_batch(texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”© ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "        batch_size: ë°°ì¹˜ í¬ê¸°\n",
    "    \n",
    "    Returns:\n",
    "        ì„ë² ë”© ë°°ì—´\n",
    "    \"\"\"\n",
    "    embeddings = embedding_model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        normalize_embeddings=config['embedding']['normalize'],\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# ì „ì²´ ì²­í¬ ì„ë² ë”© ìƒì„±\n",
    "print(f\"\\nğŸ”„ Creating embeddings for {len(chunks_df):,} chunks...\")\n",
    "all_texts = chunks_df['text'].tolist()\n",
    "all_embeddings = create_embeddings_batch(\n",
    "    all_texts,\n",
    "    batch_size=config['embedding']['batch_size']\n",
    ")\n",
    "\n",
    "print(f\"âœ… Embeddings created: {all_embeddings.shape}\")\n",
    "\n",
    "# DataFrameì— ì„ë² ë”© ì¶”ê°€\n",
    "chunks_df['embedding'] = list(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42d157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¤ Uploading vectors to Pinecone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:22<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Uploaded 641 vectors to Pinecone\n",
      "\n",
      "ğŸ“Š Index stats after upload:\n",
      "   Total vectors: 641\n",
      "   Dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "def upsert_to_pinecone(index, chunks_df: pd.DataFrame, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Pineconeì— ë²¡í„° ì—…ë¡œë“œ\n",
    "    \n",
    "    Args:\n",
    "        index: Pinecone ì¸ë±ìŠ¤\n",
    "        chunks_df: ì²­í¬ ë°ì´í„°í”„ë ˆì„\n",
    "        batch_size: ì—…ë¡œë“œ ë°°ì¹˜ í¬ê¸°\n",
    "    \"\"\"\n",
    "    total_chunks = len(chunks_df)\n",
    "    \n",
    "    for i in tqdm(range(0, total_chunks, batch_size), desc=\"Uploading to Pinecone\"):\n",
    "        batch_df = chunks_df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Pinecone ë²¡í„° í¬ë§· ìƒì„±\n",
    "        vectors = []\n",
    "        for _, row in batch_df.iterrows():\n",
    "            metadata = {\n",
    "                'text': row['text'][:1000],  # Pinecone metadata limit\n",
    "                'doc_id': str(row['doc_id']),\n",
    "                'title': str(row['title'])[:100],\n",
    "                'language': row['language'],\n",
    "                'source': row['source'],\n",
    "                'chunk_index': int(row['chunk_index']),\n",
    "                'section': str(row['section'])\n",
    "            }\n",
    "            \n",
    "            vectors.append({\n",
    "                'id': str(row['chunk_id']),\n",
    "                'values': row['embedding'].tolist(),\n",
    "                'metadata': metadata\n",
    "            })\n",
    "        \n",
    "        # ì—…ë¡œë“œ\n",
    "        index.upsert(vectors=vectors)\n",
    "        time.sleep(0.1)  # Rate limiting\n",
    "    \n",
    "    print(f\"âœ… Uploaded {total_chunks:,} vectors to Pinecone\")\n",
    "\n",
    "\n",
    "# Pineconeì— ì—…ë¡œë“œ\n",
    "print(\"\\nğŸ“¤ Uploading vectors to Pinecone...\")\n",
    "upsert_to_pinecone(index, chunks_df, batch_size=100)\n",
    "\n",
    "# ì¸ë±ìŠ¤ í†µê³„ í™•ì¸\n",
    "time.sleep(5)  # Wait for stats to update\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"\\nğŸ“Š Index stats after upload:\")\n",
    "print(f\"   Total vectors: {stats['total_vector_count']:,}\")\n",
    "print(f\"   Dimension: {stats['dimension']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d3985",
   "metadata": {},
   "source": [
    "## 4. BM25 ì¸ë±ìŠ¤ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893c7f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Creating BM25 index with improved Korean tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 641/641 [00:00<00:00, 5007.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BM25 index created with 641 documents\n",
      "âœ… BM25 index saved to: /home/dhc99/ajou-llmops-2025-2nd-semester/assignment02/artifacts/bm25_index.pkl\n",
      "   Size: 3.87 MB\n"
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì œì´ì…˜ (ê°œì„ ëœ í•œêµ­ì–´ ì§€ì›)\n",
    "import re\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ ì¹œí™”ì  í† í¬ë‚˜ì´ì €\n",
    "    - ê³µë°± ë¶„ë¦¬\n",
    "    - íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    - N-gram ìƒì„± (2-3 ê¸€ì ë‹¨ìœ„)\n",
    "    \"\"\"\n",
    "    # ì†Œë¬¸ì ë³€í™˜\n",
    "    text = text.lower()\n",
    "    \n",
    "    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)\n",
    "    text = re.sub(r'[^ê°€-í£a-z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # ê³µë°± ê¸°ë°˜ í† í°\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # ì¶”ê°€: 2-3 ê¸€ì n-gram (í•œêµ­ì–´ ê²€ìƒ‰ í–¥ìƒ)\n",
    "    ngrams = []\n",
    "    for token in tokens:\n",
    "        if len(token) >= 2:\n",
    "            # 2-gram\n",
    "            for i in range(len(token) - 1):\n",
    "                ngrams.append(token[i:i+2])\n",
    "            # 3-gram\n",
    "            if len(token) >= 3:\n",
    "                for i in range(len(token) - 2):\n",
    "                    ngrams.append(token[i:i+3])\n",
    "    \n",
    "    # í† í° + n-gram ê²°í•©\n",
    "    all_tokens = tokens + ngrams\n",
    "    \n",
    "    # ì¤‘ë³µ ì œê±° ë° í•„í„°ë§ (ë„ˆë¬´ ì§§ì€ í† í° ì œì™¸)\n",
    "    return [t for t in all_tokens if len(t) >= 1]\n",
    "\n",
    "print(\"ğŸ”„ Creating BM25 index with improved Korean tokenizer...\")\n",
    "\n",
    "# ëª¨ë“  ì²­í¬ í† í¬ë‚˜ì´ì¦ˆ\n",
    "tokenized_corpus = [tokenize(text) for text in tqdm(chunks_df['text'], desc=\"Tokenizing\")]\n",
    "\n",
    "# BM25 ì¸ë±ìŠ¤ ìƒì„± (íŒŒë¼ë¯¸í„° ì¡°ì •)\n",
    "bm25 = BM25Okapi(\n",
    "    tokenized_corpus,\n",
    "    k1=1.5,  # Term frequency saturation\n",
    "    b=0.75   # Length normalization\n",
    ")\n",
    "\n",
    "print(f\"âœ… BM25 index created with {len(tokenized_corpus):,} documents\")\n",
    "\n",
    "# BM25 ì¸ë±ìŠ¤ ì €ì¥\n",
    "bm25_file = ARTIFACTS_DIR / 'bm25_index.pkl'\n",
    "with open(bm25_file, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'bm25': bm25,\n",
    "        'tokenized_corpus': tokenized_corpus,\n",
    "        'chunk_ids': chunks_df['chunk_id'].tolist()\n",
    "    }, f)\n",
    "\n",
    "print(f\"âœ… BM25 index saved to: {bm25_file}\")\n",
    "print(f\"   Size: {bm25_file.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4481e4f",
   "metadata": {},
   "source": [
    "## 5. ì„ë² ë”© ë°ì´í„° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b5d1bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings saved to: /home/dhc99/ajou-llmops-2025-2nd-semester/assignment02/artifacts/embeddings.npy\n",
      "   Shape: (641, 1024)\n",
      "   Size: 2.50 MB\n",
      "\n",
      "âœ… Chunks metadata saved to: /home/dhc99/ajou-llmops-2025-2nd-semester/assignment02/artifacts/chunks_metadata.parquet\n"
     ]
    }
   ],
   "source": [
    "# ì„ë² ë”©ì´ í¬í•¨ëœ ì²­í¬ ë°ì´í„° ì €ì¥\n",
    "# (ì„ë² ë”©ì€ numpy arrayì´ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬)\n",
    "embeddings_file = ARTIFACTS_DIR / 'embeddings.npy'\n",
    "np.save(embeddings_file, all_embeddings)\n",
    "print(f\"âœ… Embeddings saved to: {embeddings_file}\")\n",
    "print(f\"   Shape: {all_embeddings.shape}\")\n",
    "print(f\"   Size: {embeddings_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥ (ì„ë² ë”© ì œì™¸)\n",
    "chunks_metadata = chunks_df.drop(columns=['embedding']).copy()\n",
    "metadata_file = ARTIFACTS_DIR / 'chunks_metadata.parquet'\n",
    "chunks_metadata.to_parquet(metadata_file, index=False)\n",
    "print(f\"\\nâœ… Chunks metadata saved to: {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95f94b",
   "metadata": {},
   "source": [
    "## 6. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a143417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Test Query: ëŒ€í•œë¯¼êµ­ì—ì„œ ìµœì´ˆë¡œ ì¶œì‹œëœ ìŠ¤ë‚µì€?\n",
      "   Expected Answer: ìƒˆìš°ê¹¡\n",
      "\n",
      "ğŸ“Š Dense Retrieval Results:\n",
      "================================================================================\n",
      "\n",
      "1. Score: 0.8713\n",
      "   ID: 6467462-0-1_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.8713\n",
      "   ID: 6484373-0-0_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.8713\n",
      "   ID: 6484373-0-1_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Score: 0.8713\n",
      "   ID: 6484373-0-2_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Score: 0.8713\n",
      "   ID: 6467462-0-0_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dense ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ë°ì´í„°ì…‹ì— ì‹¤ì œë¡œ ìˆëŠ” ì§ˆë¬¸ ì‚¬ìš©)\n",
    "test_query = \"ëŒ€í•œë¯¼êµ­ì—ì„œ ìµœì´ˆë¡œ ì¶œì‹œëœ ìŠ¤ë‚µì€?\"\n",
    "print(f\"ğŸ” Test Query: {test_query}\")\n",
    "print(f\"   Expected Answer: ìƒˆìš°ê¹¡\\n\")\n",
    "\n",
    "# ì¿¼ë¦¬ ì„ë² ë”©\n",
    "query_embedding = embedding_model.encode(\n",
    "    test_query,\n",
    "    normalize_embeddings=config['embedding']['normalize']\n",
    ")\n",
    "\n",
    "# Pinecone ê²€ìƒ‰\n",
    "results = index.query(\n",
    "    vector=query_embedding.tolist(),\n",
    "    top_k=5,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Dense Retrieval Results:\")\n",
    "print(\"=\"*80)\n",
    "for i, match in enumerate(results['matches'], 1):\n",
    "    print(f\"\\n{i}. Score: {match['score']:.4f}\")\n",
    "    print(f\"   ID: {match['id']}\")\n",
    "    print(f\"   Title: {match['metadata'].get('title', 'N/A')}\")\n",
    "    print(f\"   Text: {match['metadata']['text'][:200]}...\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85c28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” BM25 Test Query: ëŒ€í•œë¯¼êµ­ì—ì„œ ìµœì´ˆë¡œ ì¶œì‹œëœ ìŠ¤ë‚µì€?\n",
      "   Expected Answer: ìƒˆìš°ê¹¡\n",
      "\n",
      "ğŸ”¤ Tokenized Query: ['ëŒ€í•œë¯¼êµ­ì—ì„œ', 'ìµœì´ˆë¡œ', 'ì¶œì‹œëœ', 'ìŠ¤ë‚µì€', 'ëŒ€í•œ', 'í•œë¯¼', 'ë¯¼êµ­', 'êµ­ì—', 'ì—ì„œ', 'ëŒ€í•œë¯¼', 'í•œë¯¼êµ­', 'ë¯¼êµ­ì—', 'êµ­ì—ì„œ', 'ìµœì´ˆ', 'ì´ˆë¡œ', 'ìµœì´ˆë¡œ', 'ì¶œì‹œ', 'ì‹œëœ', 'ì¶œì‹œëœ', 'ìŠ¤ë‚µ']...\n",
      "\n",
      "ğŸ“Š BM25 Retrieval Results:\n",
      "================================================================================\n",
      "\n",
      "1. Score: 28.4991\n",
      "   ID: 6484386-0-2_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Score: 28.4991\n",
      "   ID: 6484386-0-1_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Score: 28.4991\n",
      "   ID: 6484386-0-0_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Score: 28.4991\n",
      "   ID: 6484373-0-1_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Score: 28.4991\n",
      "   ID: 6467462-0-1_chunk_1\n",
      "   Title: ë†ì‹¬ê·¸ë£¹\n",
      "   Text: 'ë†ì‹¬'ìœ¼ë¡œ ë°”ê¾¸ê³  ë¼ë©´ì‹œì¥ì— ë³¸ê²©ì ìœ¼ë¡œ ë›°ì–´ë“ ë‹¤. ì´ ê³¼ì •ì—ì„œ í”¼ë¥¼ ë‚˜ëˆˆ ë‘ í˜•ì œëŠ” ì˜ì ˆí–ˆê³ , ê²°êµ­ ë¡¯ë°ê·¸ë£¹ê³¼ ë†ì‹¬ê·¸ë£¹ìœ¼ë¡œ ê°ˆë¼ì§€ëŠ” ê³„ê¸°ê°€ ëë‹¤. 1971ë…„ 12ì›”, ëŒ€í•œë¯¼êµ­ ìµœì´ˆì˜ ìŠ¤ë‚µì¸ 'ìƒˆìš°ê¹¡'ì„ ì¶œì‹œí–ˆë‹¤. ì§­ì§¤í•˜ë©´ì„œ ê³ ì†Œí•˜ê³  ë°”ì‚­í•œ ì‹ê°ì˜ ìƒˆìš°ê¹¡ì€ ë…íŠ¹í•œ ì´ë¦„ê³¼ í•¨ê»˜ ì‹œì¥ì—ì„œ ëŒí’ì„ ì¼ìœ¼í‚¤ë©° ì¶œì‹œ 3ê°œì›” ë§Œì— ë†ì‹¬ ë§¤ì¶œì„ 2ë°° ê°€ê¹Œìš´ ì„±ì¥ì„ ê°€ì ¸ë‹¤...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# BM25 ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ” BM25 Test Query: {test_query}\")\n",
    "print(f\"   Expected Answer: ìƒˆìš°ê¹¡\\n\")\n",
    "\n",
    "tokenized_query = tokenize(test_query)\n",
    "print(f\"ğŸ”¤ Tokenized Query: {tokenized_query[:20]}...\")  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ\n",
    "\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Top-K ê²°ê³¼\n",
    "top_k_indices = np.argsort(bm25_scores)[::-1][:5]\n",
    "\n",
    "print(\"\\nğŸ“Š BM25 Retrieval Results:\")\n",
    "print(\"=\"*80)\n",
    "for i, idx in enumerate(top_k_indices, 1):\n",
    "    chunk = chunks_df.iloc[idx]\n",
    "    print(f\"\\n{i}. Score: {bm25_scores[idx]:.4f}\")\n",
    "    print(f\"   ID: {chunk['chunk_id']}\")\n",
    "    print(f\"   Title: {chunk['title']}\")\n",
    "    print(f\"   Text: {chunk['text'][:200]}...\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8384d",
   "metadata": {},
   "source": [
    "## 7. Pinecone í”„ë¡œì íŠ¸ ê³µìœ  ì•ˆë‚´\n",
    "\n",
    "**ì¤‘ìš”: Pinecone í”„ë¡œì íŠ¸ì— ê°•ì‚¬ë¥¼ ì´ˆëŒ€í•´ì•¼ í•©ë‹ˆë‹¤!**\n",
    "\n",
    "### ë‹¨ê³„:\n",
    "1. Pinecone ì½˜ì†” ì ‘ì†: https://app.pinecone.io/\n",
    "2. í”„ë¡œì íŠ¸ ì„¤ì • â†’ Members\n",
    "3. ê°•ì‚¬ ì´ë©”ì¼ ì´ˆëŒ€ (ê¶Œí•œ: Viewer ë˜ëŠ” Editor)\n",
    "4. ì´ˆëŒ€ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜\n",
    "5. ì œì¶œë¬¼ì— í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80498853",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ Indexing Complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Š Summary:\")\n",
    "print(f\"   Pinecone Index: {index_name}\")\n",
    "print(f\"   Total Vectors: {stats['total_vector_count']:,}\")\n",
    "print(f\"   Embedding Model: {config['embedding']['model_name']}\")\n",
    "print(f\"   BM25 Index: {bm25_file}\")\n",
    "print(f\"\\nğŸ“ Artifacts:\")\n",
    "print(f\"   - {embeddings_file}\")\n",
    "print(f\"   - {bm25_file}\")\n",
    "print(f\"   - {metadata_file}\")\n",
    "print(\"\\nâš ï¸  Remember to invite instructor to Pinecone project!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
