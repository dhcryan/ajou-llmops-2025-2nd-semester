{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week02 - Advanced Reasoning Techniques\n",
    "\n",
    "본 노트북은 고급 추론 프롬프트 엔지니어링 기법들을 실습합니다.\n",
    "\n",
    "## 다룰 기법들\n",
    "1. **Zero-shot**: 예시 없이 직접 추론\n",
    "2. **Few-shot**: 소수 예시로 패턴 학습\n",
    "3. **Chain of Thought (CoT)**: 단계별 추론\n",
    "4. **Least-to-Most**: 문제 분해 후 순차 해결\n",
    "5. **Tree of Thoughts (ToT)**: 다중 경로 탐색\n",
    "6. **ReAct**: 추론과 행동의 반복\n",
    "7. **Program-Aided Language Model (PAL)**: 코드를 통한 정확한 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 및 import\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import functools\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 라이브러리\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    !pip install openai\n",
    "    from openai import OpenAI\n",
    "\n",
    "# 설정\n",
    "client = OpenAI()  # 환경변수에서 API 키 자동 로드\n",
    "\n",
    "# 헬퍼 함수들\n",
    "def run_ollama(model: str, prompt: str) -> str:\n",
    "    \"\"\"Ollama 모델 실행\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model],\n",
    "            input=prompt,\n",
    "            text=True,\n",
    "            capture_output=True,\n",
    "            timeout=60\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"Error: Timeout\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def run_openai(prompt: str, model: str = \"gpt-5-mini\", **kwargs) -> str:\n",
    "    \"\"\"OpenAI 모델 실행\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            **kwargs\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def run_openai_with_messages(messages: List[Dict], model: str = \"gpt-5-mini\", **kwargs) -> str:\n",
    "    \"\"\"OpenAI 모델 실행 (메시지 리스트 사용)\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            **kwargs\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Zero-shot\n",
    "\n",
    "**핵심 아이디어**: 예시 없이 문제·출력 포맷만으로 답을 얻음\n",
    "\n",
    "- 장점: 준비 비용↓, 일반화 테스트에 유리\n",
    "- 단점: 포맷 일탈·과잉창작 위험\n",
    "- 설계 팁: \"**역할** + **태스크** + **출력 스키마/제약**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot 감성 분류 ===\n",
      "Ollama (llama3.1:8b):\n",
      "```\n",
      "{\n",
      "  \"label\": \"positive\",\n",
      "  \"reason\": \"Expresses satisfaction with fast delivery and good packaging\"\n",
      "}\n",
      "```\n",
      "\n",
      "OpenAI (gpt-5-mini):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Zero-shot - 고객 리뷰 감성 분류\n",
    "zero_shot_prompt = \"\"\"Role: sentiment classifier.\n",
    "Task: Classify review as positive|negative|neutral and give a one-line reason.\n",
    "Return ONLY JSON {label, reason}.\n",
    "Review: --- 배송 빠르고 포장 깔끔, 재구매 의사 있어요 ---\"\"\"\n",
    "\n",
    "print(\"=== Zero-shot 감성 분류 ===\")\n",
    "print(\"Ollama (llama3.1:8b):\")\n",
    "zero_shot_ollama = run_ollama(\"llama3.1:8b\", zero_shot_prompt)\n",
    "print(zero_shot_ollama)\n",
    "\n",
    "print(\"\\nOpenAI (gpt-5-mini):\")\n",
    "zero_shot_openai = run_openai(zero_shot_prompt, max_completion_tokens=120)\n",
    "print(zero_shot_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot 다양한 예시 테스트 ===\n",
      "예시 1: 배송이 늦고 포장도 찢어졌어요\n",
      "결과: \n",
      "\n",
      "예시 2: 가격은 비싸지만 품질이 좋네요\n",
      "결과: \n",
      "\n",
      "예시 3: 보통 수준입니다. 특별하지 않아요\n",
      "결과: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot 다른 예시들\n",
    "zero_shot_examples = [\n",
    "    \"배송이 늦고 포장도 찢어졌어요\",\n",
    "    \"가격은 비싸지만 품질이 좋네요\",\n",
    "    \"보통 수준입니다. 특별하지 않아요\"\n",
    "]\n",
    "\n",
    "print(\"=== Zero-shot 다양한 예시 테스트 ===\")\n",
    "for i, review in enumerate(zero_shot_examples, 1):\n",
    "    prompt = f\"\"\"Role: sentiment classifier.\n",
    "Task: Classify review as positive|negative|neutral and give a one-line reason.\n",
    "Return ONLY JSON {{label, reason}}.\n",
    "Review: --- {review} ---\"\"\"\n",
    "    \n",
    "    result = run_openai(prompt, max_completion_tokens=100)\n",
    "    print(f\"예시 {i}: {review}\")\n",
    "    print(f\"결과: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Few-shot\n",
    "\n",
    "**핵심 아이디어**: 소수 예시로 의도·포맷을 학습 유도\n",
    "\n",
    "- 장점: 포맷 안정화·경계 케이스 교정\n",
    "- 단점: 데이터 누수/편향·컨텍스트 사용량↑\n",
    "- 설계 팁: \"좋은/나쁜\" 예시를 대조로 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Few-shot 의도 분류 ===\n",
      "Ollama:\n",
      "A nice example!\n",
      "\n",
      "Based on the context of the sentence, I would classify it as:\n",
      "\n",
      "{\"intent\": \"exchange\"}\n",
      "\n",
      "The reason is that the customer is complaining about a discrepancy between the color in the picture and the actual product, which implies they want to exchange the item for one with the correct color. The phrase \"바꿀 수 있나요?\" (Can I change/replace it?) further supports this interpretation.\n",
      "\n",
      "Am I correct?\n",
      "\n",
      "OpenAI:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Few-shot - 주문 의도 분류\n",
    "few_shot_prompt = \"\"\"Task: intent classification -> refund|exchange|question. JSON {intent}.\n",
    "Examples:\n",
    "- '개봉 전인데 환불 원해요' -> {\"intent\": \"refund\"}\n",
    "- '사이즈 안 맞아 교환할래요' -> {\"intent\": \"exchange\"}\n",
    "- '배송 언제 오나요?' -> {\"intent\": \"question\"}\n",
    "Now classify: --- 색상이 사진과 달라요, 바꿀 수 있나요? ---\"\"\"\n",
    "\n",
    "print(\"=== Few-shot 의도 분류 ===\")\n",
    "print(\"Ollama:\")\n",
    "few_shot_ollama = run_ollama(\"llama3.1:8b\", few_shot_prompt)\n",
    "print(few_shot_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "few_shot_openai = run_openai(few_shot_prompt, max_completion_tokens=80)\n",
    "print(few_shot_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot vs Few-shot 성능 비교 ===\n",
      "\n",
      "입력: 불량품이라서 돈 돌려받고 싶어요\n",
      "Zero-shot: \n",
      "Few-shot: \n",
      "\n",
      "입력: 다른 색깔로 바꿔주세요\n",
      "Zero-shot: \n",
      "Few-shot: \n",
      "\n",
      "입력: 언제까지 사용할 수 있나요?\n",
      "Zero-shot: \n",
      "Few-shot: \n"
     ]
    }
   ],
   "source": [
    "# Few-shot 성능 비교: Zero-shot vs Few-shot\n",
    "test_inputs = [\n",
    "    \"불량품이라서 돈 돌려받고 싶어요\",\n",
    "    \"다른 색깔로 바꿔주세요\",\n",
    "    \"언제까지 사용할 수 있나요?\"\n",
    "]\n",
    "\n",
    "print(\"=== Zero-shot vs Few-shot 성능 비교 ===\")\n",
    "\n",
    "for text in test_inputs:\n",
    "    print(f\"\\n입력: {text}\")\n",
    "    \n",
    "    # Zero-shot\n",
    "    zero_prompt = f\"Classify customer intent -> refund|exchange|question. JSON only.\\nText: {text}\"\n",
    "    zero_result = run_openai(zero_prompt, max_completion_tokens=50)\n",
    "    print(f\"Zero-shot: {zero_result}\")\n",
    "    \n",
    "    # Few-shot  \n",
    "    few_prompt = f\"\"\"Examples:\n",
    "- '환불하고 싶어요' -> {{\"intent\": \"refund\"}}\n",
    "- '교환 가능한가요?' -> {{\"intent\": \"exchange\"}}\n",
    "- '배송 정보 알려주세요' -> {{\"intent\": \"question\"}}\n",
    "Classify: {text}\"\"\"\n",
    "    few_result = run_openai(few_prompt, max_completion_tokens=50)\n",
    "    print(f\"Few-shot: {few_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chain of Thought (CoT)\n",
    "\n",
    "**핵심 아이디어**: 단계별 추론을 유도해 오류율↓\n",
    "\n",
    "- 장점: 복잡 산술·논리·계획 문제에 강함\n",
    "- 설계 팁: \"단계별로 사고하되, 마지막에 '정답만' 별도 표기\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoT 수학 문제 ===\n",
      "Ollama:\n",
      "Here is the solution:\n",
      "\n",
      "{\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"operator\": \"*\",\n",
      "      \"operands\": [\n",
      "        {\n",
      "          \"value\": 30,\n",
      "          \"digits\": [\"3\", \"0\"]\n",
      "        },\n",
      "        {\n",
      "          \"value\": 20,\n",
      "          \"digits\": [\"2\", \"0\"]\n",
      "        }\n",
      "      ],\n",
      "      \"result\": {\n",
      "        \"value\": 600,\n",
      "        \"digits\": [\"6\", \"0\", \"0\"]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"operator\": \"*\",\n",
      "      \"operands\": [\n",
      "        {\n",
      "          \"value\": 10,\n",
      "          \"digits\": [\"1\", \"0\"]\n",
      "        },\n",
      "        {\n",
      "          \"value\": 20,\n",
      "          \"digits\": [\"2\", \"0\"]\n",
      "        }\n",
      "      ],\n",
      "      \"result\": {\n",
      "        \"value\": 200,\n",
      "        \"digits\": [\"2\", \"0\", \"0\"]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"operator\": \"+\",\n",
      "      \"operands\": [\n",
      "        {\n",
      "          \"value\": 600,\n",
      "          \"digits\": [\"6\", \"0\", \"0\"]\n",
      "        },\n",
      "        {\n",
      "          \"value\": 200,\n",
      "          \"digits\": [\"2\", \"0\", \"0\"]\n",
      "        }\n",
      "      ],\n",
      "      \"result\": {\n",
      "        \"value\": 800,\n",
      "        \"digits\": [\"8\", \"0\", \"0\"]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"final_answer\": 800\n",
      "}\n",
      "\n",
      "OpenAI:\n",
      "\n",
      "\n",
      "실제 정답: 1702\n"
     ]
    }
   ],
   "source": [
    "# 3. Chain of Thought - 수학 문제\n",
    "cot_math_prompt = \"\"\"Solve step by step. Provide JSON:\n",
    "{\"steps\": [...], \"final_answer\": number}\n",
    "Q: 37 * 46\"\"\"\n",
    "\n",
    "print(\"=== CoT 수학 문제 ===\")\n",
    "print(\"Ollama:\")\n",
    "cot_math_ollama = run_ollama(\"llama3.1:8b\", cot_math_prompt)\n",
    "print(cot_math_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "cot_math_openai = run_openai(cot_math_prompt, max_completion_tokens=250)\n",
    "print(cot_math_openai)\n",
    "\n",
    "# 정답 확인\n",
    "print(f\"\\n실제 정답: {37 * 46}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoT 논리 추론 ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CoT 논리 추론 문제\n",
    "cot_logic_prompt = \"\"\"Think step by step and provide your reasoning.\n",
    "Problem: 모든 고양이는 동물이다. 솜이는 고양이다. 따라서 솜이는 동물이다.\n",
    "이 논증의 유효성을 단계별로 분석하고 JSON으로 답하시오:\n",
    "{\"steps\": [...], \"conclusion\": \"valid|invalid\", \"reason\": \"...\"}\"\"\"\n",
    "\n",
    "print(\"=== CoT 논리 추론 ===\")\n",
    "cot_logic_result = run_openai(cot_logic_prompt, max_completion_tokens=300)\n",
    "print(cot_logic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoT vs 직접 답변 비교 ===\n",
      "직접 답변: \n",
      "\n",
      "CoT 답변: \n",
      "\n",
      "문제 해석에 따른 정답:\n",
      "해석1 (모든 사과를 나누어줌): 24-24+0-3 = -3 (불가능)\n",
      "해석2 (4명이서 나누어 먹음): 24/4=6, 6-3=3개 남음\n"
     ]
    }
   ],
   "source": [
    "# CoT vs 직접 답변 비교\n",
    "word_problem = \"Sarah가 사과 24개를 가지고 있다. 친구 3명에게 똑같이 나누어주고, 자신은 3개를 더 먹었다. 남은 사과는 몇 개인가?\"\n",
    "\n",
    "print(\"=== CoT vs 직접 답변 비교 ===\")\n",
    "\n",
    "# 직접 답변\n",
    "direct_prompt = f\"문제: {word_problem}\\n답:\"\n",
    "direct_result = run_openai(direct_prompt, max_completion_tokens=100)\n",
    "print(f\"직접 답변: {direct_result}\")\n",
    "\n",
    "# CoT 답변\n",
    "cot_prompt = f\"\"\"문제를 단계별로 해결하세요.\n",
    "JSON 형식: {{\"steps\": [...], \"final_answer\": number}}\n",
    "문제: {word_problem}\"\"\"\n",
    "cot_result = run_openai(cot_prompt, max_completion_tokens=200)\n",
    "print(f\"\\nCoT 답변: {cot_result}\")\n",
    "\n",
    "# 수동 계산으로 정답 확인\n",
    "# Sarah 24개 -> 친구 3명에게 나누어줌 (24/3 = 8개씩) -> 24-24 = 0개\n",
    "# 아니면 Sarah가 친구들과 함께 4명이서 나누어 먹는다는 의미일 수도: 24/4 = 6개씩\n",
    "# Sarah가 3개 더 먹음 -> 6-3 = 3개 남음\n",
    "print(\"\\n문제 해석에 따른 정답:\")\n",
    "print(\"해석1 (모든 사과를 나누어줌): 24-24+0-3 = -3 (불가능)\")\n",
    "print(\"해석2 (4명이서 나누어 먹음): 24/4=6, 6-3=3개 남음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Least-to-Most\n",
    "\n",
    "**핵심 아이디어**: 문제를 작은 하위문제로 분해 → 순서대로 해결\n",
    "\n",
    "- 장점: 장문 추론, 제약 충돌 해결에 유리\n",
    "- 설계 템플릿: 1) 하위목표 나열 2) 각 목표 해결 3) 최종 통합 답 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Least-to-Most 점심 추천 ===\n",
      "Ollama:\n",
      "예산 10만원, 3명, 비건 1명을 위한 점심 코스 추천 (2곳)에는 다음과 같은 해결책이 있습니다.\n",
      "\n",
      "| 식당 | 인당가격 | 총액 | 비건옵션 | 특징 |\n",
      "| --- | --- | --- | --- | --- |\n",
      "| 가 | 30,000원/인 | 90,000원 | ☕️ | 주말에만 운영 |\n",
      "| 나 | 25,000원/인 | 75,000원 | 🌱 | 비건 식당 |\n",
      "\n",
      "**해결 방법**\n",
      "\n",
      "1. **하위목표**: \n",
      "    - 비용: 10만원 이내\n",
      "    - 인원: 3명 (비건 1명)\n",
      "    - 점심 코스 추천 (2곳)\n",
      "\n",
      "2. **각 목표 해결**\n",
      "   - **식당 1:** 가\n",
      "     - 가격: 30,000원/인\n",
      "     - 총 비용: 90,000원\n",
      "     - 비건 옵션: ☕️\n",
      "     - 특징: 주말에만 운영\n",
      "\n",
      "   - **식당 2:** 나\n",
      "     - 가격: 25,000원/인\n",
      "     - 총 비용: 75,000원\n",
      "     - 비건 옵션: 🌱\n",
      "     - 특징: 비건 식당\n",
      "\n",
      "3. **통합 솔루션**\n",
      "   - 두 식당 중에서 인당 가격이 저렴하고 비건 옵션이 있는 나 식당을 선택합니다.\n",
      "   - 총 비용은 75,000원으로 10만원 이내에 점심 코스를 해결할 수 있습니다.\n",
      "\n",
      "결과적으로 나 식당 (비건 옵션)으로 비용은 90,000원에서 75,000원으로 줄어든 것을 확인할 수 있습니다.\n",
      "\n",
      "=== OpenAI ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Least-to-Most - 복합 제약 문제\n",
    "ltm_prompt = \"\"\"Use least-to-most decomposition.\n",
    "Problem: 예산 10만원, 3명, 비건 1명을 위한 점심 코스 추천 (2곳), 총액≤10만원\n",
    "\n",
    "Step 1: 하위목표 나열\n",
    "Step 2: 각 목표 해결  \n",
    "Step 3: 통합 솔루션\n",
    "\n",
    "Return markdown table: | 식당 | 인당가격 | 총액 | 비건옵션 | 특징 |\"\"\"\n",
    "\n",
    "print(\"=== Least-to-Most 점심 추천 ===\")\n",
    "print(\"Ollama:\")\n",
    "ltm_ollama = run_ollama(\"llama3.1:8b\", ltm_prompt)\n",
    "print(ltm_ollama)\n",
    "\n",
    "print(\"\\n=== OpenAI ===\")\n",
    "ltm_openai = run_openai(ltm_prompt, max_completion_tokens=400)\n",
    "print(ltm_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Least-to-Most 프로젝트 계획 ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Least-to-Most 프로젝트 계획\n",
    "ltm_project_prompt = \"\"\"Use least-to-most approach to create a project plan.\n",
    "Goal: \"웹사이트 리뉴얼 프로젝트 (4주, 팀 5명, 예산 500만원)\"\n",
    "\n",
    "1) 주요 하위 작업들을 식별\n",
    "2) 각 작업의 리소스와 시간 할당\n",
    "3) 최종 통합 계획표 작성\n",
    "\n",
    "Output format: JSON with {\"subtasks\": [...], \"timeline\": {...}, \"final_plan\": \"...\"}\"\"\"\n",
    "\n",
    "print(\"=== Least-to-Most 프로젝트 계획 ===\")\n",
    "ltm_project_result = run_openai(ltm_project_prompt, max_completion_tokens=500)\n",
    "print(ltm_project_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree of Thoughts (ToT)\n",
    "\n",
    "**핵심 아이디어**: 여러 추론 경로(생각 가지) 생성 → 자체평가 후 최고안 선택\n",
    "\n",
    "- 장점: 탐색적 문제(기획·전략·설계)에 강함\n",
    "- 설계 템플릿: 가지 생성 N(보통 3) → 각 가지 장단점 평가 → 최종 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tree of Thoughts 학습 전략 ===\n",
      "Ollama:\n",
      "Here are three distinct study plans using the Tree of Thoughts approach to achieve a balanced 4-week study strategy for high school students in math, English, and science:\n",
      "\n",
      "**Plan 1: Intensive Focus**\n",
      "\n",
      "* **Approach:** Divide the 4 weeks into four main topics (2 in math, 1 in English, 1 in science). Each week, focus on one topic exclusively, allocating 70% of study time to it.\n",
      "* **Pros:**\n",
      "\t+ Deep understanding of each topic\n",
      "\t+ Improved retention and recall\n",
      "\t+ Time management skills development\n",
      "* **Cons:**\n",
      "\t+ Risk of neglecting other important topics\n",
      "\t+ Limited exposure to different subjects\n",
      "\t+ Potential burnout due to intense focus on one topic\n",
      "* **Rating:** 7/10\n",
      "\n",
      "**Plan 2: Balanced Approach**\n",
      "\n",
      "* **Approach:** Divide the 4 weeks into four equal parts, allocating 30% of study time to each subject. Rotate topics within each subject area (e.g., algebra and geometry in math).\n",
      "* **Pros:**\n",
      "\t+ Better balance between subjects\n",
      "\t+ Reduced risk of neglecting important topics\n",
      "\t+ Improved overall understanding of multiple subjects\n",
      "* **Cons:**\n",
      "\t+ May not allow for deep dives into individual topics\n",
      "\t+ Requires more time management skills to rotate topics effectively\n",
      "* **Rating:** 8.5/10\n",
      "\n",
      "**Plan 3: Priority-Based Study**\n",
      "\n",
      "* **Approach:** Prioritize topics based on upcoming exams, quizzes, or project deadlines. Allocate study time accordingly (80% for high-priority topics, 20% for low-priority ones).\n",
      "* **Pros:**\n",
      "\t+ Effective use of limited study time\n",
      "\t+ Reduced stress due to targeted focus on critical topics\n",
      "\t+ Improved grades and performance in important assessments\n",
      "* **Cons:**\n",
      "\t+ May lead to neglect of other important topics\n",
      "\t+ Requires frequent adjustments based on changing priorities\n",
      "* **Rating:** 8/10\n",
      "\n",
      "**Best Plan:** \"Balanced Approach\" (Plan 2)\n",
      "\n",
      "Reason: This plan strikes a balance between focus and breadth, allowing for deep understanding of individual topics while also ensuring that all subjects receive sufficient attention.\n",
      "\n",
      "=== OpenAI ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Tree of Thoughts - 학습 전략\n",
    "tot_prompt = \"\"\"Generate 3 distinct study plans using Tree of Thoughts.\n",
    "Goal: \"고등학생을 위한 4주 공부전략(수학·영어·과학 균형)\"\n",
    "\n",
    "For each plan:\n",
    "1) Outline the approach\n",
    "2) List pros and cons\n",
    "3) Rate effectiveness (1-10)\n",
    "\n",
    "Finally, pick BEST plan with 1-line rationale.\n",
    "\n",
    "Return JSON: {\"plans\": [{\"name\": \"...\", \"outline\": \"...\", \"pros\": [...], \"cons\": [...], \"rating\": N}], \"best_choice\": {\"name\": \"...\", \"reason\": \"...\"}}\"\"\"\n",
    "\n",
    "print(\"=== Tree of Thoughts 학습 전략 ===\")\n",
    "print(\"Ollama:\")\n",
    "tot_ollama = run_ollama(\"llama3.1:8b\", tot_prompt)\n",
    "print(tot_ollama)\n",
    "\n",
    "print(\"\\n=== OpenAI ===\")\n",
    "tot_openai = run_openai(tot_prompt, max_completion_tokens=700)\n",
    "print(tot_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tree of Thoughts 비즈니스 전략 ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ToT 비즈니스 전략\n",
    "tot_business_prompt = \"\"\"Tree of Thoughts for business strategy.\n",
    "Challenge: \"스타트업의 첫 제품 출시 전략 (B2B SaaS)\"\n",
    "\n",
    "Generate 3 different approaches:\n",
    "1) 각 접근법의 핵심 아이디어\n",
    "2) 예상 비용과 시간\n",
    "3) 리스크와 기회요인\n",
    "4) 성공 가능성 평가\n",
    "\n",
    "Choose the best strategy and explain why.\"\"\"\n",
    "\n",
    "print(\"=== Tree of Thoughts 비즈니스 전략 ===\")\n",
    "tot_business_result = run_openai(tot_business_prompt, max_completion_tokens=600)\n",
    "print(tot_business_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ReAct (Reasoning + Acting)\n",
    "\n",
    "**핵심 아이디어**: Reason(추론) + Action(툴 호출) + Observation(결과 반영) 루프\n",
    "\n",
    "- 장점: 실시간 데이터/DB/계산과 결합\n",
    "- 설계 팁: 툴 스키마(이름/파라미터/설명) 명확히"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 11) (615955541.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNow do this pattern for: \"오늘 달러 환율 확인하고 투자 조언 한 줄\"\"\"\"\u001b[39m\n                                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 11)\n"
     ]
    }
   ],
   "source": [
    "# 6. ReAct - 시뮬레이션 (Ollama는 툴 호출 미지원이므로 텍스트로 흉내)\n",
    "react_simulation_prompt = \"\"\"Follow ReAct pattern (Reasoning + Action + Observation).\n",
    "Task: \"내일 서울 날씨를 확인하고 한 줄 요약해줘\"\n",
    "\n",
    "Thought: I should check the weather for Seoul tomorrow.\n",
    "Action: get_weather(city='Seoul', date='tomorrow')\n",
    "Observation: (simulate) 'Sunny, 27°C, light breeze'\n",
    "Thought: Now I can provide a summary.\n",
    "Final Answer: 내일 서울은 맑고 27도로 쾌적한 날씨가 예상됩니다.\n",
    "\n",
    "Now do this pattern for: \"오늘 달러 환율 확인하고 투자 조언 한 줄\"\"\"\"\n",
    "\n",
    "print(\"=== ReAct 시뮬레이션 ===\")\n",
    "print(\"Ollama:\")\n",
    "react_ollama = run_ollama(\"llama3.1:8b\", react_simulation_prompt)\n",
    "print(react_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "react_openai = run_openai(react_simulation_prompt, max_completion_tokens=300)\n",
    "print(react_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct 실제 Function Calling (OpenAI)\n",
    "# 실제 도구 정의\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"더미 날씨 API\"\"\"\n",
    "    weather_data = {\n",
    "        \"서울\": \"맑음, 25도\",\n",
    "        \"부산\": \"흐림, 28도\", \n",
    "        \"Seoul\": \"Sunny, 25°C\"\n",
    "    }\n",
    "    return weather_data.get(city, \"날씨 정보 없음\")\n",
    "\n",
    "def calculate_math(expression: str) -> str:\n",
    "    \"\"\"안전한 수식 계산\"\"\"\n",
    "    try:\n",
    "        # 안전한 수식만 계산 (eval 대신 간단한 파싱)\n",
    "        if re.match(r'^[0-9+\\-*/().\\s]+$', expression):\n",
    "            result = eval(expression)  # 실제로는 더 안전한 파서 사용 권장\n",
    "            return str(result)\n",
    "        else:\n",
    "            return \"지원되지 않는 수식\"\n",
    "    except:\n",
    "        return \"계산 오류\"\n",
    "\n",
    "# Function Calling 도구 정의\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"도시의 날씨 정보를 가져옵니다\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"도시 이름\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate_math\", \n",
    "            \"description\": \"수학 계산을 수행합니다\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\"type\": \"string\", \"description\": \"계산할 수식\"}\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== ReAct with Function Calling ===\")\n",
    "\n",
    "# 첫 번째 요청\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"서울 날씨 확인하고 25 * 30 계산해서 요약해줘\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# 도구 호출 처리\n",
    "if response.choices[0].message.tool_calls:\n",
    "    messages.append(response.choices[0].message)\n",
    "    \n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "        elif function_name == \"calculate_math\":\n",
    "            result = calculate_math(arguments[\"expression\"])\n",
    "        else:\n",
    "            result = \"Unknown function\"\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": function_name,\n",
    "            \"content\": str(result)\n",
    "        })\n",
    "        print(f\"Tool used: {function_name} -> {result}\")\n",
    "    \n",
    "    # 최종 응답 생성\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFinal Answer:\")\n",
    "    print(final_response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"No tool calls made:\")\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Program-Aided Language Model (PAL)\n",
    "\n",
    "**핵심 아이디어**: 모델이 코드(예: Python)를 작성 → 실행 결과를 답변에 사용\n",
    "\n",
    "- 장점: 수치/조합/탐색 정확도↑, 재현성↑\n",
    "- 설계 팁: 안전 실행 환경(샌드박스), 금지 모듈 차단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. PAL - 수학 함수 생성 및 실행\n",
    "pal_prompt = \"\"\"Write Python function gcd_list(nums: list[int]) -> int using math.gcd and functools.reduce.\n",
    "Return ONLY the code, no explanation.\"\"\"\n",
    "\n",
    "print(\"=== PAL 코드 생성 ===\")\n",
    "print(\"Ollama:\")\n",
    "pal_ollama = run_ollama(\"llama3.1:8b\", pal_prompt)\n",
    "print(pal_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "pal_openai = run_openai(pal_prompt, max_completion_tokens=200)\n",
    "print(pal_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAL 코드 실행 (안전한 방식)\n",
    "def safe_execute_code(code: str, test_input: list) -> str:\n",
    "    \"\"\"안전하게 코드를 실행\"\"\"\n",
    "    try:\n",
    "        # 위험한 키워드 체크\n",
    "        dangerous_keywords = ['import os', 'import sys', 'open(', 'exec', 'eval']\n",
    "        for keyword in dangerous_keywords:\n",
    "            if keyword in code:\n",
    "                return f\"위험한 코드 감지: {keyword}\"\n",
    "        \n",
    "        # 허용된 import만 추가\n",
    "        safe_code = \"import math\\nimport functools\\n\" + code\n",
    "        \n",
    "        # 코드 실행\n",
    "        local_env = {}\n",
    "        exec(safe_code, {\"math\": math, \"functools\": functools}, local_env)\n",
    "        \n",
    "        # 함수 실행\n",
    "        if 'gcd_list' in local_env:\n",
    "            result = local_env['gcd_list'](test_input)\n",
    "            return str(result)\n",
    "        else:\n",
    "            return \"함수 gcd_list를 찾을 수 없음\"\n",
    "    except Exception as e:\n",
    "        return f\"실행 오류: {str(e)}\"\n",
    "\n",
    "# 테스트\n",
    "test_numbers = [24, 60, 36]\n",
    "print(f\"=== PAL 코드 실행 테스트: gcd_list({test_numbers}) ===\")\n",
    "\n",
    "# OpenAI 코드 실행\n",
    "openai_result = safe_execute_code(pal_openai, test_numbers)\n",
    "print(f\"OpenAI 코드 실행 결과: {openai_result}\")\n",
    "\n",
    "# 정답 확인 (수동 계산)\n",
    "actual_gcd = functools.reduce(math.gcd, test_numbers)\n",
    "print(f\"실제 GCD({test_numbers}): {actual_gcd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PAL 복잡한 계산 ===\n",
      "생성된 코드:\n",
      "\n",
      "\n",
      "실행 결과: \n",
      "수동 계산 검증: 128.0 cm²\n"
     ]
    }
   ],
   "source": [
    "# PAL 복잡한 계산 예시\n",
    "complex_pal_prompt = \"\"\"Write Python code to solve this problem:\n",
    "\"사다리꼴의 넓이를 구하시오. 윗변 12cm, 아랫변 20cm, 높이 8cm\"\n",
    "\n",
    "Return executable Python code that calculates and prints the result.\"\"\"\n",
    "\n",
    "print(\"=== PAL 복잡한 계산 ===\")\n",
    "complex_code = run_openai(complex_pal_prompt, max_completion_tokens=200)\n",
    "print(\"생성된 코드:\")\n",
    "print(complex_code)\n",
    "\n",
    "# 안전 실행\n",
    "def safe_execute_calculation(code: str) -> str:\n",
    "    try:\n",
    "        # 출력 캡처를 위한 StringIO 사용\n",
    "        from io import StringIO\n",
    "        import sys\n",
    "        \n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = captured_output = StringIO()\n",
    "        \n",
    "        # 코드에서 위험 요소 제거 후 실행\n",
    "        clean_code = code.replace('```python', '').replace('```', '')\n",
    "        exec(clean_code)\n",
    "        \n",
    "        sys.stdout = old_stdout\n",
    "        return captured_output.getvalue().strip()\n",
    "    except Exception as e:\n",
    "        if 'sys' in locals():\n",
    "            sys.stdout = old_stdout\n",
    "        return f\"실행 오류: {str(e)}\"\n",
    "\n",
    "result = safe_execute_calculation(complex_code)\n",
    "print(f\"\\n실행 결과: {result}\")\n",
    "\n",
    "# 수동 검증\n",
    "area = (12 + 20) * 8 / 2\n",
    "print(f\"수동 계산 검증: {area} cm²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기법 비교 및 성능 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 문제에 대한 다양한 기법 비교\n",
    "comparison_problem = \"23 × 47 + 15 × 32를 계산하시오\"\n",
    "\n",
    "print(\"=== 기법별 성능 비교: 복합 계산 문제 ===\")\n",
    "print(f\"문제: {comparison_problem}\")\n",
    "print(f\"정답: {23 * 47 + 15 * 32}\")\n",
    "print()\n",
    "\n",
    "# 1. Zero-shot\n",
    "zero_shot = run_openai(f\"Calculate: {comparison_problem}\", max_completion_tokens=100)\n",
    "print(f\"Zero-shot: {zero_shot}\")\n",
    "\n",
    "# 2. Chain of Thought\n",
    "cot = run_openai(f\"Solve step by step: {comparison_problem}\", max_completion_tokens=200)\n",
    "print(f\"\\nCoT: {cot}\")\n",
    "\n",
    "# 3. PAL\n",
    "pal_calc_prompt = f\"Write Python code to calculate: {comparison_problem}\"\n",
    "pal_code = run_openai(pal_calc_prompt, max_completion_tokens=150)\n",
    "pal_result = safe_execute_calculation(pal_code)\n",
    "print(f\"\\nPAL 코드: {pal_code}\")\n",
    "print(f\"PAL 결과: {pal_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 품질 평가 메트릭\n",
    "def evaluate_reasoning_quality(response: str, expected_answer: any) -> dict:\n",
    "    \"\"\"추론 품질 평가\"\"\"\n",
    "    metrics = {\n",
    "        'has_steps': bool(re.search(r'(step|단계|first|then|next)', response, re.I)),\n",
    "        'has_calculation': bool(re.search(r'[0-9]+\\s*[+\\-*/×÷]\\s*[0-9]+', response)),\n",
    "        'has_final_answer': bool(re.search(r'(답|answer|result|결과)', response, re.I)),\n",
    "        'length': len(response),\n",
    "        'confidence_words': len(re.findall(r'(확실|certain|clear|obvious)', response, re.I))\n",
    "    }\n",
    "    \n",
    "    # 숫자 정확도 체크 (간단한 버전)\n",
    "    numbers = re.findall(r'\\b\\d+\\b', response)\n",
    "    if numbers:\n",
    "        try:\n",
    "            final_number = int(numbers[-1])  # 마지막 숫자를 최종 답으로 간주\n",
    "            metrics['correct_answer'] = (final_number == expected_answer)\n",
    "        except:\n",
    "            metrics['correct_answer'] = False\n",
    "    else:\n",
    "        metrics['correct_answer'] = False\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 평가 실행\n",
    "expected = 23 * 47 + 15 * 32\n",
    "\n",
    "evaluations = {\n",
    "    'Zero-shot': evaluate_reasoning_quality(zero_shot, expected),\n",
    "    'CoT': evaluate_reasoning_quality(cot, expected),\n",
    "    'PAL': evaluate_reasoning_quality(pal_result, expected)\n",
    "}\n",
    "\n",
    "print(\"\\n=== 추론 품질 평가 ===\")\n",
    "for method, metrics in evaluations.items():\n",
    "    print(f\"\\n{method}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종합 실습: 하이브리드 접근법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 하이브리드 추론 시스템 테스트 ===\n",
      "\n",
      "--- 테스트 케이스 1 ---\n",
      "문제: 125 × 8 + 75 ÷ 3을 계산하시오\n",
      "분류된 문제 유형: math\n",
      "사용된 기법: PAL, CoT\n",
      "\n",
      "PAL 결과: \n",
      "\n",
      "CoT 결과: ...\n",
      "\n",
      "--- 테스트 케이스 2 ---\n",
      "문제: 새로운 온라인 쇼핑몰 런칭 전략을 3가지 제안해주세요\n",
      "분류된 문제 유형: planning\n",
      "사용된 기법: ToT\n",
      "\n",
      "ToT 결과: ...\n",
      "\n",
      "--- 테스트 케이스 3 ---\n",
      "문제: '배송이 빨라서 만족해요'를 분류하세요\n",
      "분류된 문제 유형: classification\n",
      "사용된 기법: Few-shot\n",
      "\n",
      "Few-shot 결과: ...\n",
      "\n",
      "--- 테스트 케이스 4 ---\n",
      "문제: 인공지능의 장단점을 설명해주세요\n",
      "분류된 문제 유형: general\n",
      "사용된 기법: CoT\n",
      "\n",
      "CoT 결과: ...\n"
     ]
    }
   ],
   "source": [
    "# 여러 기법을 조합한 하이브리드 시스템\n",
    "def hybrid_reasoning_system(problem: str, problem_type: str = \"auto\") -> dict:\n",
    "    \"\"\"문제 유형에 따라 최적 기법을 자동 선택하는 시스템\"\"\"\n",
    "    \n",
    "    # 문제 유형 자동 분류\n",
    "    if problem_type == \"auto\":\n",
    "        if re.search(r'\\d+\\s*[+\\-*/×÷]\\s*\\d+', problem):\n",
    "            problem_type = \"math\"\n",
    "        elif re.search(r'(전략|계획|방법|approach|strategy)', problem, re.I):\n",
    "            problem_type = \"planning\"\n",
    "        elif re.search(r'(분류|classify|sentiment)', problem, re.I):\n",
    "            problem_type = \"classification\"\n",
    "        else:\n",
    "            problem_type = \"general\"\n",
    "    \n",
    "    results = {\"problem_type\": problem_type, \"methods_used\": [], \"results\": {}}\n",
    "    \n",
    "    # 문제 유형별 최적 기법 적용\n",
    "    if problem_type == \"math\":\n",
    "        # 수학 문제: PAL + CoT 조합\n",
    "        results[\"methods_used\"] = [\"PAL\", \"CoT\"]\n",
    "        \n",
    "        # PAL 시도\n",
    "        pal_prompt = f\"Write Python code to solve: {problem}\"\n",
    "        pal_code = run_openai(pal_prompt, max_completion_tokens=200)\n",
    "        pal_result = safe_execute_calculation(pal_code)\n",
    "        results[\"results\"][\"PAL\"] = {\"code\": pal_code, \"result\": pal_result}\n",
    "        \n",
    "        # CoT 백업\n",
    "        cot_prompt = f\"Solve step by step with detailed reasoning: {problem}\"\n",
    "        cot_result = run_openai(cot_prompt, max_completion_tokens=300)\n",
    "        results[\"results\"][\"CoT\"] = cot_result\n",
    "        \n",
    "    elif problem_type == \"planning\":\n",
    "        # 기획 문제: ToT\n",
    "        results[\"methods_used\"] = [\"ToT\"]\n",
    "        tot_prompt = f\"\"\"Generate 3 different approaches to: {problem}\n",
    "For each: outline, pros/cons, feasibility rating.\n",
    "Choose the best approach.\"\"\"\n",
    "        tot_result = run_openai(tot_prompt, max_completion_tokens=500)\n",
    "        results[\"results\"][\"ToT\"] = tot_result\n",
    "        \n",
    "    elif problem_type == \"classification\":\n",
    "        # 분류 문제: Few-shot\n",
    "        results[\"methods_used\"] = [\"Few-shot\"]\n",
    "        few_shot_prompt = f\"\"\"Examples of classification:\n",
    "Input: \"좋은 제품이에요\" -> positive\n",
    "Input: \"별로예요\" -> negative  \n",
    "Input: \"보통입니다\" -> neutral\n",
    "\n",
    "Now classify: {problem}\"\"\"\n",
    "        few_shot_result = run_openai(few_shot_prompt, max_completion_tokens=100)\n",
    "        results[\"results\"][\"Few-shot\"] = few_shot_result\n",
    "        \n",
    "    else:\n",
    "        # 일반 문제: CoT\n",
    "        results[\"methods_used\"] = [\"CoT\"]\n",
    "        cot_prompt = f\"Think step by step and solve: {problem}\"\n",
    "        cot_result = run_openai(cot_prompt,max_completion_tokens=300)\n",
    "        results[\"results\"][\"CoT\"] = cot_result\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 테스트 케이스들\n",
    "test_cases = [\n",
    "    \"125 × 8 + 75 ÷ 3을 계산하시오\",\n",
    "    \"새로운 온라인 쇼핑몰 런칭 전략을 3가지 제안해주세요\", \n",
    "    \"'배송이 빨라서 만족해요'를 분류하세요\",\n",
    "    \"인공지능의 장단점을 설명해주세요\"\n",
    "]\n",
    "\n",
    "print(\"=== 하이브리드 추론 시스템 테스트 ===\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n--- 테스트 케이스 {i} ---\")\n",
    "    print(f\"문제: {test_case}\")\n",
    "    \n",
    "    result = hybrid_reasoning_system(test_case)\n",
    "    \n",
    "    print(f\"분류된 문제 유형: {result['problem_type']}\")\n",
    "    print(f\"사용된 기법: {', '.join(result['methods_used'])}\")\n",
    "    \n",
    "    for method, output in result['results'].items():\n",
    "        if isinstance(output, dict):\n",
    "            print(f\"\\n{method} 결과: {output.get('result', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"\\n{method} 결과: {output[:200]}...\")  # 처음 200자만 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리 및 베스트 프랙티스\n",
    "\n",
    "### 기법별 적용 가이드\n",
    "\n",
    "| 기법 | 적용 상황 | 장점 | 단점 |\n",
    "|------|-----------|------|------|\n",
    "| Zero-shot | 간단한 분류, 빠른 테스트 | 빠름, 간단 | 불안정한 포맷 |\n",
    "| Few-shot | 포맷 안정화 필요시 | 일관된 출력 | 컨텍스트 소모 |\n",
    "| CoT | 논리적 추론, 수학 문제 | 높은 정확도 | 긴 응답 시간 |\n",
    "| Least-to-Most | 복잡한 제약 문제 | 체계적 접근 | 복잡한 설계 |\n",
    "| ToT | 창의적 문제, 전략 수립 | 다양한 관점 | 높은 비용 |\n",
    "| ReAct | 실시간 데이터 필요 | 최신 정보 | 도구 의존성 |\n",
    "| PAL | 정확한 계산 | 100% 정확 | 코드 안전성 |\n",
    "\n",
    "### 실무 권장사항\n",
    "\n",
    "1. **문제 유형 자동 분류** 시스템 구축\n",
    "2. **하이브리드 접근법**으로 여러 기법 조합\n",
    "3. **성능 모니터링**을 통한 지속적 개선\n",
    "4. **안전성 검증** (특히 PAL 사용시)\n",
    "5. **비용 효율성** 고려한 기법 선택"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ajou-llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
